{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf2c87b0-bfe1-4ea8-a3db-b1e3cd88470b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Jun__8_16:49:14_PDT_2022\n",
      "Cuda compilation tools, release 11.7, V11.7.99\n",
      "Build cuda_11.7.r11.7/compiler.31442593_0\n",
      "torch:  1.11 ; cuda:  cu113\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "787e1aac-16ab-45f7-8973-a27cb696c96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator, DatasetEvaluators\n",
    "from detectron2.engine import DefaultTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3292c3b5-3cfe-4caa-908d-04fb78706468",
   "metadata": {},
   "source": [
    "# Fisheye Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81fa366f-37ad-4cb2-864f-a977ac447694",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Dataset 'fisheye8k_train' is already registered!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_coco_instances\n\u001b[0;32m----> 2\u001b[0m \u001b[43mregister_coco_instances\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfisheye8k_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/workspace/FishEye8k/dataset/Fisheye8K_all_including_train/train/train.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/workspace/FishEye8k/dataset/Fisheye8K_all_including_train/train/images\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m register_coco_instances(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfisheye8k_val\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}, \n\u001b[1;32m      6\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/workspace/FishEye8k/dataset/Fisheye8K_all_including_train/test/test.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      7\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/workspace/FishEye8k/dataset/Fisheye8K_all_including_train/test/images\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/data/datasets/coco.py:541\u001b[0m, in \u001b[0;36mregister_coco_instances\u001b[0;34m(name, metadata, json_file, image_root)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image_root, (\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)), image_root\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# 1. register a function which returns dicts\u001b[39;00m\n\u001b[0;32m--> 541\u001b[0m \u001b[43mDatasetCatalog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_coco_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;66;03m# 2. Optionally, add metadata about this dataset,\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# since they might be useful in evaluation, visualization or logging\u001b[39;00m\n\u001b[1;32m    545\u001b[0m MetadataCatalog\u001b[38;5;241m.\u001b[39mget(name)\u001b[38;5;241m.\u001b[39mset(\n\u001b[1;32m    546\u001b[0m     json_file\u001b[38;5;241m=\u001b[39mjson_file, image_root\u001b[38;5;241m=\u001b[39mimage_root, evaluator_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoco\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetadata\n\u001b[1;32m    547\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/data/catalog.py:37\u001b[0m, in \u001b[0;36m_DatasetCatalog.register\u001b[0;34m(self, name, func)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    name (str): the name that identifies a dataset, e.g. \"coco_2014_train\".\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    func (callable): a callable which takes no arguments and returns a list of dicts.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m        It must return the same results if called multiple times.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must register a function with `DatasetCatalog.register`!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is already registered!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m[name] \u001b[38;5;241m=\u001b[39m func\n",
      "\u001b[0;31mAssertionError\u001b[0m: Dataset 'fisheye8k_train' is already registered!"
     ]
    }
   ],
   "source": [
    "register_coco_instances(\"fisheye8k_train\", {}, \n",
    "                        \"/workspace/FishEye8k/dataset/Fisheye8K_all_including_train/train/train.json\", \n",
    "                        \"/workspace/FishEye8k/dataset/Fisheye8K_all_including_train/train/images\")\n",
    "register_coco_instances(\"fisheye8k_val\", {}, \n",
    "                        \"/workspace/FishEye8k/dataset/Fisheye8K_all_including_train/test/test.json\", \n",
    "                        \"/workspace/FishEye8k/dataset/Fisheye8K_all_including_train/test/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c86372-073f-4057-978c-9142072878f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/01 18:13:48 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/01 18:13:49 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/01 18:13:49 d2.data.datasets.coco]: \u001b[0mLoaded 5288 images in COCO format from /workspace/FishEye8k/dataset/Fisheye8K_all_including_train/train/train.json\n",
      "\u001b[32m[04/01 18:13:49 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 5288 images left.\n",
      "\u001b[32m[04/01 18:13:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[04/01 18:13:49 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[04/01 18:13:49 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[04/01 18:13:49 d2.data.common]: \u001b[0mSerializing 5288 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/01 18:13:49 d2.data.common]: \u001b[0mSerialized dataset takes 4.66 MiB\n",
      "\u001b[32m[04/01 18:13:49 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=32\n",
      "\u001b[32m[04/01 18:13:49 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (6, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (20, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/01 18:13:49 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[04/01 18:14:35 d2.utils.events]: \u001b[0m eta: 0:09:09  iter: 19  total_loss: 3.698  loss_cls: 1.943  loss_box_reg: 0.3966  loss_rpn_cls: 1.021  loss_rpn_loc: 0.2996    time: 1.9180  last_time: 1.7007  data_time: 0.9120  last_data_time: 0.5298   lr: 1.6068e-05  max_mem: 45332M\n",
      "\u001b[32m[04/01 18:15:15 d2.utils.events]: \u001b[0m eta: 0:09:04  iter: 39  total_loss: 2.474  loss_cls: 1.617  loss_box_reg: 0.4158  loss_rpn_cls: 0.1503  loss_rpn_loc: 0.2575    time: 1.9783  last_time: 2.3698  data_time: 0.6254  last_data_time: 0.7745   lr: 3.2718e-05  max_mem: 45332M\n",
      "\u001b[32m[04/01 18:15:56 d2.utils.events]: \u001b[0m eta: 0:08:39  iter: 59  total_loss: 1.905  loss_cls: 1.011  loss_box_reg: 0.4574  loss_rpn_cls: 0.1081  loss_rpn_loc: 0.2573    time: 1.9921  last_time: 2.3148  data_time: 0.6562  last_data_time: 0.7267   lr: 4.9367e-05  max_mem: 45332M\n",
      "\u001b[32m[04/01 18:16:36 d2.utils.events]: \u001b[0m eta: 0:07:56  iter: 79  total_loss: 1.479  loss_cls: 0.6611  loss_box_reg: 0.4838  loss_rpn_cls: 0.09542  loss_rpn_loc: 0.2442    time: 2.0024  last_time: 2.0241  data_time: 0.6399  last_data_time: 0.5828   lr: 6.6017e-05  max_mem: 45332M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/01 18:17:17 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/01 18:17:17 d2.data.datasets.coco]: \u001b[0mLoaded 2712 images in COCO format from /workspace/FishEye8k/dataset/Fisheye8K_all_including_train/test/test.json\n",
      "\u001b[32m[04/01 18:17:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[04/01 18:17:17 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[04/01 18:17:17 d2.data.common]: \u001b[0mSerializing 2712 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/01 18:17:17 d2.data.common]: \u001b[0mSerialized dataset takes 2.01 MiB\n",
      "\u001b[32m[04/01 18:17:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 2712 batches\n",
      "\u001b[32m[04/01 18:17:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/2712. Dataloading: 0.0008 s/iter. Inference: 0.3029 s/iter. Eval: 0.0002 s/iter. Total: 0.3039 s/iter. ETA=0:13:40\n",
      "\u001b[32m[04/01 18:17:32 d2.evaluation.evaluator]: \u001b[0mInference done 29/2712. Dataloading: 0.0010 s/iter. Inference: 0.2912 s/iter. Eval: 0.0002 s/iter. Total: 0.2925 s/iter. ETA=0:13:04\n",
      "\u001b[32m[04/01 18:17:37 d2.evaluation.evaluator]: \u001b[0mInference done 47/2712. Dataloading: 0.0011 s/iter. Inference: 0.2870 s/iter. Eval: 0.0003 s/iter. Total: 0.2885 s/iter. ETA=0:12:48\n",
      "\u001b[32m[04/01 18:17:42 d2.evaluation.evaluator]: \u001b[0mInference done 64/2712. Dataloading: 0.0011 s/iter. Inference: 0.2921 s/iter. Eval: 0.0003 s/iter. Total: 0.2936 s/iter. ETA=0:12:57\n",
      "\u001b[32m[04/01 18:17:47 d2.evaluation.evaluator]: \u001b[0mInference done 81/2712. Dataloading: 0.0012 s/iter. Inference: 0.2934 s/iter. Eval: 0.0003 s/iter. Total: 0.2950 s/iter. ETA=0:12:56\n",
      "\u001b[32m[04/01 18:17:52 d2.evaluation.evaluator]: \u001b[0mInference done 99/2712. Dataloading: 0.0021 s/iter. Inference: 0.2903 s/iter. Eval: 0.0003 s/iter. Total: 0.2928 s/iter. ETA=0:12:44\n",
      "\u001b[32m[04/01 18:17:57 d2.evaluation.evaluator]: \u001b[0mInference done 117/2712. Dataloading: 0.0027 s/iter. Inference: 0.2891 s/iter. Eval: 0.0003 s/iter. Total: 0.2921 s/iter. ETA=0:12:38\n",
      "\u001b[32m[04/01 18:18:02 d2.evaluation.evaluator]: \u001b[0mInference done 135/2712. Dataloading: 0.0031 s/iter. Inference: 0.2875 s/iter. Eval: 0.0003 s/iter. Total: 0.2909 s/iter. ETA=0:12:29\n",
      "\u001b[32m[04/01 18:18:08 d2.evaluation.evaluator]: \u001b[0mInference done 153/2712. Dataloading: 0.0028 s/iter. Inference: 0.2875 s/iter. Eval: 0.0003 s/iter. Total: 0.2907 s/iter. ETA=0:12:23\n",
      "\u001b[32m[04/01 18:18:13 d2.evaluation.evaluator]: \u001b[0mInference done 170/2712. Dataloading: 0.0026 s/iter. Inference: 0.2886 s/iter. Eval: 0.0003 s/iter. Total: 0.2916 s/iter. ETA=0:12:21\n",
      "\u001b[32m[04/01 18:18:18 d2.evaluation.evaluator]: \u001b[0mInference done 188/2712. Dataloading: 0.0029 s/iter. Inference: 0.2886 s/iter. Eval: 0.0003 s/iter. Total: 0.2919 s/iter. ETA=0:12:16\n",
      "\u001b[32m[04/01 18:18:23 d2.evaluation.evaluator]: \u001b[0mInference done 207/2712. Dataloading: 0.0027 s/iter. Inference: 0.2876 s/iter. Eval: 0.0003 s/iter. Total: 0.2907 s/iter. ETA=0:12:08\n",
      "\u001b[32m[04/01 18:18:29 d2.evaluation.evaluator]: \u001b[0mInference done 226/2712. Dataloading: 0.0026 s/iter. Inference: 0.2867 s/iter. Eval: 0.0003 s/iter. Total: 0.2897 s/iter. ETA=0:12:00\n",
      "\u001b[32m[04/01 18:18:34 d2.evaluation.evaluator]: \u001b[0mInference done 244/2712. Dataloading: 0.0028 s/iter. Inference: 0.2864 s/iter. Eval: 0.0003 s/iter. Total: 0.2896 s/iter. ETA=0:11:54\n",
      "\u001b[32m[04/01 18:18:39 d2.evaluation.evaluator]: \u001b[0mInference done 262/2712. Dataloading: 0.0027 s/iter. Inference: 0.2869 s/iter. Eval: 0.0003 s/iter. Total: 0.2900 s/iter. ETA=0:11:50\n",
      "\u001b[32m[04/01 18:18:44 d2.evaluation.evaluator]: \u001b[0mInference done 279/2712. Dataloading: 0.0026 s/iter. Inference: 0.2876 s/iter. Eval: 0.0003 s/iter. Total: 0.2906 s/iter. ETA=0:11:46\n",
      "\u001b[32m[04/01 18:18:49 d2.evaluation.evaluator]: \u001b[0mInference done 298/2712. Dataloading: 0.0025 s/iter. Inference: 0.2866 s/iter. Eval: 0.0003 s/iter. Total: 0.2895 s/iter. ETA=0:11:38\n",
      "\u001b[32m[04/01 18:18:55 d2.evaluation.evaluator]: \u001b[0mInference done 316/2712. Dataloading: 0.0024 s/iter. Inference: 0.2866 s/iter. Eval: 0.0003 s/iter. Total: 0.2894 s/iter. ETA=0:11:33\n",
      "\u001b[32m[04/01 18:19:00 d2.evaluation.evaluator]: \u001b[0mInference done 333/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0003 s/iter. Total: 0.2897 s/iter. ETA=0:11:29\n",
      "\u001b[32m[04/01 18:19:05 d2.evaluation.evaluator]: \u001b[0mInference done 351/2712. Dataloading: 0.0023 s/iter. Inference: 0.2869 s/iter. Eval: 0.0003 s/iter. Total: 0.2896 s/iter. ETA=0:11:23\n",
      "\u001b[32m[04/01 18:19:10 d2.evaluation.evaluator]: \u001b[0mInference done 368/2712. Dataloading: 0.0023 s/iter. Inference: 0.2872 s/iter. Eval: 0.0003 s/iter. Total: 0.2899 s/iter. ETA=0:11:19\n",
      "\u001b[32m[04/01 18:19:15 d2.evaluation.evaluator]: \u001b[0mInference done 385/2712. Dataloading: 0.0022 s/iter. Inference: 0.2875 s/iter. Eval: 0.0003 s/iter. Total: 0.2901 s/iter. ETA=0:11:14\n",
      "\u001b[32m[04/01 18:19:20 d2.evaluation.evaluator]: \u001b[0mInference done 403/2712. Dataloading: 0.0024 s/iter. Inference: 0.2875 s/iter. Eval: 0.0003 s/iter. Total: 0.2903 s/iter. ETA=0:11:10\n",
      "\u001b[32m[04/01 18:19:25 d2.evaluation.evaluator]: \u001b[0mInference done 421/2712. Dataloading: 0.0023 s/iter. Inference: 0.2875 s/iter. Eval: 0.0003 s/iter. Total: 0.2902 s/iter. ETA=0:11:04\n",
      "\u001b[32m[04/01 18:19:31 d2.evaluation.evaluator]: \u001b[0mInference done 438/2712. Dataloading: 0.0023 s/iter. Inference: 0.2882 s/iter. Eval: 0.0003 s/iter. Total: 0.2908 s/iter. ETA=0:11:01\n",
      "\u001b[32m[04/01 18:19:36 d2.evaluation.evaluator]: \u001b[0mInference done 456/2712. Dataloading: 0.0022 s/iter. Inference: 0.2879 s/iter. Eval: 0.0003 s/iter. Total: 0.2905 s/iter. ETA=0:10:55\n",
      "\u001b[32m[04/01 18:19:41 d2.evaluation.evaluator]: \u001b[0mInference done 473/2712. Dataloading: 0.0022 s/iter. Inference: 0.2879 s/iter. Eval: 0.0006 s/iter. Total: 0.2908 s/iter. ETA=0:10:51\n",
      "\u001b[32m[04/01 18:19:46 d2.evaluation.evaluator]: \u001b[0mInference done 491/2712. Dataloading: 0.0022 s/iter. Inference: 0.2879 s/iter. Eval: 0.0006 s/iter. Total: 0.2908 s/iter. ETA=0:10:45\n",
      "\u001b[32m[04/01 18:19:51 d2.evaluation.evaluator]: \u001b[0mInference done 509/2712. Dataloading: 0.0021 s/iter. Inference: 0.2877 s/iter. Eval: 0.0006 s/iter. Total: 0.2905 s/iter. ETA=0:10:40\n",
      "\u001b[32m[04/01 18:19:56 d2.evaluation.evaluator]: \u001b[0mInference done 528/2712. Dataloading: 0.0021 s/iter. Inference: 0.2873 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:10:33\n",
      "\u001b[32m[04/01 18:20:01 d2.evaluation.evaluator]: \u001b[0mInference done 546/2712. Dataloading: 0.0022 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2899 s/iter. ETA=0:10:27\n",
      "\u001b[32m[04/01 18:20:07 d2.evaluation.evaluator]: \u001b[0mInference done 563/2712. Dataloading: 0.0022 s/iter. Inference: 0.2879 s/iter. Eval: 0.0006 s/iter. Total: 0.2907 s/iter. ETA=0:10:24\n",
      "\u001b[32m[04/01 18:20:12 d2.evaluation.evaluator]: \u001b[0mInference done 581/2712. Dataloading: 0.0021 s/iter. Inference: 0.2877 s/iter. Eval: 0.0006 s/iter. Total: 0.2905 s/iter. ETA=0:10:19\n",
      "\u001b[32m[04/01 18:20:17 d2.evaluation.evaluator]: \u001b[0mInference done 599/2712. Dataloading: 0.0021 s/iter. Inference: 0.2878 s/iter. Eval: 0.0006 s/iter. Total: 0.2906 s/iter. ETA=0:10:14\n",
      "\u001b[32m[04/01 18:20:22 d2.evaluation.evaluator]: \u001b[0mInference done 617/2712. Dataloading: 0.0021 s/iter. Inference: 0.2878 s/iter. Eval: 0.0006 s/iter. Total: 0.2906 s/iter. ETA=0:10:08\n",
      "\u001b[32m[04/01 18:20:28 d2.evaluation.evaluator]: \u001b[0mInference done 635/2712. Dataloading: 0.0022 s/iter. Inference: 0.2875 s/iter. Eval: 0.0005 s/iter. Total: 0.2903 s/iter. ETA=0:10:03\n",
      "\u001b[32m[04/01 18:20:33 d2.evaluation.evaluator]: \u001b[0mInference done 653/2712. Dataloading: 0.0023 s/iter. Inference: 0.2872 s/iter. Eval: 0.0005 s/iter. Total: 0.2902 s/iter. ETA=0:09:57\n",
      "\u001b[32m[04/01 18:20:38 d2.evaluation.evaluator]: \u001b[0mInference done 670/2712. Dataloading: 0.0023 s/iter. Inference: 0.2875 s/iter. Eval: 0.0005 s/iter. Total: 0.2904 s/iter. ETA=0:09:52\n",
      "\u001b[32m[04/01 18:20:43 d2.evaluation.evaluator]: \u001b[0mInference done 688/2712. Dataloading: 0.0022 s/iter. Inference: 0.2877 s/iter. Eval: 0.0005 s/iter. Total: 0.2905 s/iter. ETA=0:09:47\n",
      "\u001b[32m[04/01 18:20:48 d2.evaluation.evaluator]: \u001b[0mInference done 707/2712. Dataloading: 0.0022 s/iter. Inference: 0.2874 s/iter. Eval: 0.0005 s/iter. Total: 0.2903 s/iter. ETA=0:09:42\n",
      "\u001b[32m[04/01 18:20:54 d2.evaluation.evaluator]: \u001b[0mInference done 725/2712. Dataloading: 0.0022 s/iter. Inference: 0.2873 s/iter. Eval: 0.0005 s/iter. Total: 0.2902 s/iter. ETA=0:09:36\n",
      "\u001b[32m[04/01 18:20:59 d2.evaluation.evaluator]: \u001b[0mInference done 743/2712. Dataloading: 0.0022 s/iter. Inference: 0.2873 s/iter. Eval: 0.0005 s/iter. Total: 0.2901 s/iter. ETA=0:09:31\n",
      "\u001b[32m[04/01 18:21:04 d2.evaluation.evaluator]: \u001b[0mInference done 762/2712. Dataloading: 0.0021 s/iter. Inference: 0.2870 s/iter. Eval: 0.0005 s/iter. Total: 0.2899 s/iter. ETA=0:09:25\n",
      "\u001b[32m[04/01 18:21:09 d2.evaluation.evaluator]: \u001b[0mInference done 780/2712. Dataloading: 0.0021 s/iter. Inference: 0.2868 s/iter. Eval: 0.0005 s/iter. Total: 0.2896 s/iter. ETA=0:09:19\n",
      "\u001b[32m[04/01 18:21:14 d2.evaluation.evaluator]: \u001b[0mInference done 798/2712. Dataloading: 0.0021 s/iter. Inference: 0.2869 s/iter. Eval: 0.0005 s/iter. Total: 0.2897 s/iter. ETA=0:09:14\n",
      "\u001b[32m[04/01 18:21:20 d2.evaluation.evaluator]: \u001b[0mInference done 816/2712. Dataloading: 0.0021 s/iter. Inference: 0.2869 s/iter. Eval: 0.0005 s/iter. Total: 0.2896 s/iter. ETA=0:09:09\n",
      "\u001b[32m[04/01 18:21:25 d2.evaluation.evaluator]: \u001b[0mInference done 834/2712. Dataloading: 0.0022 s/iter. Inference: 0.2867 s/iter. Eval: 0.0005 s/iter. Total: 0.2895 s/iter. ETA=0:09:03\n",
      "\u001b[32m[04/01 18:21:30 d2.evaluation.evaluator]: \u001b[0mInference done 852/2712. Dataloading: 0.0021 s/iter. Inference: 0.2867 s/iter. Eval: 0.0005 s/iter. Total: 0.2895 s/iter. ETA=0:08:58\n",
      "\u001b[32m[04/01 18:21:35 d2.evaluation.evaluator]: \u001b[0mInference done 869/2712. Dataloading: 0.0022 s/iter. Inference: 0.2867 s/iter. Eval: 0.0005 s/iter. Total: 0.2896 s/iter. ETA=0:08:53\n",
      "\u001b[32m[04/01 18:21:40 d2.evaluation.evaluator]: \u001b[0mInference done 886/2712. Dataloading: 0.0022 s/iter. Inference: 0.2869 s/iter. Eval: 0.0005 s/iter. Total: 0.2898 s/iter. ETA=0:08:49\n",
      "\u001b[32m[04/01 18:21:45 d2.evaluation.evaluator]: \u001b[0mInference done 903/2712. Dataloading: 0.0022 s/iter. Inference: 0.2871 s/iter. Eval: 0.0005 s/iter. Total: 0.2899 s/iter. ETA=0:08:44\n",
      "\u001b[32m[04/01 18:21:50 d2.evaluation.evaluator]: \u001b[0mInference done 921/2712. Dataloading: 0.0023 s/iter. Inference: 0.2869 s/iter. Eval: 0.0005 s/iter. Total: 0.2898 s/iter. ETA=0:08:38\n",
      "\u001b[32m[04/01 18:21:55 d2.evaluation.evaluator]: \u001b[0mInference done 939/2712. Dataloading: 0.0022 s/iter. Inference: 0.2868 s/iter. Eval: 0.0005 s/iter. Total: 0.2896 s/iter. ETA=0:08:33\n",
      "\u001b[32m[04/01 18:22:00 d2.evaluation.evaluator]: \u001b[0mInference done 957/2712. Dataloading: 0.0022 s/iter. Inference: 0.2868 s/iter. Eval: 0.0005 s/iter. Total: 0.2896 s/iter. ETA=0:08:28\n",
      "\u001b[32m[04/01 18:22:06 d2.evaluation.evaluator]: \u001b[0mInference done 975/2712. Dataloading: 0.0022 s/iter. Inference: 0.2868 s/iter. Eval: 0.0005 s/iter. Total: 0.2896 s/iter. ETA=0:08:23\n",
      "\u001b[32m[04/01 18:22:11 d2.evaluation.evaluator]: \u001b[0mInference done 993/2712. Dataloading: 0.0023 s/iter. Inference: 0.2865 s/iter. Eval: 0.0004 s/iter. Total: 0.2894 s/iter. ETA=0:08:17\n",
      "\u001b[32m[04/01 18:22:16 d2.evaluation.evaluator]: \u001b[0mInference done 1010/2712. Dataloading: 0.0023 s/iter. Inference: 0.2866 s/iter. Eval: 0.0004 s/iter. Total: 0.2896 s/iter. ETA=0:08:12\n",
      "\u001b[32m[04/01 18:22:21 d2.evaluation.evaluator]: \u001b[0mInference done 1029/2712. Dataloading: 0.0024 s/iter. Inference: 0.2863 s/iter. Eval: 0.0004 s/iter. Total: 0.2893 s/iter. ETA=0:08:06\n",
      "\u001b[32m[04/01 18:22:26 d2.evaluation.evaluator]: \u001b[0mInference done 1047/2712. Dataloading: 0.0024 s/iter. Inference: 0.2863 s/iter. Eval: 0.0004 s/iter. Total: 0.2893 s/iter. ETA=0:08:01\n",
      "\u001b[32m[04/01 18:22:31 d2.evaluation.evaluator]: \u001b[0mInference done 1065/2712. Dataloading: 0.0024 s/iter. Inference: 0.2862 s/iter. Eval: 0.0004 s/iter. Total: 0.2893 s/iter. ETA=0:07:56\n",
      "\u001b[32m[04/01 18:22:36 d2.evaluation.evaluator]: \u001b[0mInference done 1083/2712. Dataloading: 0.0024 s/iter. Inference: 0.2861 s/iter. Eval: 0.0004 s/iter. Total: 0.2891 s/iter. ETA=0:07:50\n",
      "\u001b[32m[04/01 18:22:41 d2.evaluation.evaluator]: \u001b[0mInference done 1100/2712. Dataloading: 0.0024 s/iter. Inference: 0.2862 s/iter. Eval: 0.0004 s/iter. Total: 0.2891 s/iter. ETA=0:07:46\n",
      "\u001b[32m[04/01 18:22:47 d2.evaluation.evaluator]: \u001b[0mInference done 1119/2712. Dataloading: 0.0024 s/iter. Inference: 0.2860 s/iter. Eval: 0.0004 s/iter. Total: 0.2891 s/iter. ETA=0:07:40\n",
      "\u001b[32m[04/01 18:22:52 d2.evaluation.evaluator]: \u001b[0mInference done 1136/2712. Dataloading: 0.0024 s/iter. Inference: 0.2863 s/iter. Eval: 0.0004 s/iter. Total: 0.2893 s/iter. ETA=0:07:35\n",
      "\u001b[32m[04/01 18:22:57 d2.evaluation.evaluator]: \u001b[0mInference done 1153/2712. Dataloading: 0.0024 s/iter. Inference: 0.2865 s/iter. Eval: 0.0004 s/iter. Total: 0.2895 s/iter. ETA=0:07:31\n",
      "\u001b[32m[04/01 18:23:02 d2.evaluation.evaluator]: \u001b[0mInference done 1171/2712. Dataloading: 0.0025 s/iter. Inference: 0.2863 s/iter. Eval: 0.0004 s/iter. Total: 0.2894 s/iter. ETA=0:07:25\n",
      "\u001b[32m[04/01 18:23:07 d2.evaluation.evaluator]: \u001b[0mInference done 1189/2712. Dataloading: 0.0024 s/iter. Inference: 0.2863 s/iter. Eval: 0.0004 s/iter. Total: 0.2893 s/iter. ETA=0:07:20\n",
      "\u001b[32m[04/01 18:23:12 d2.evaluation.evaluator]: \u001b[0mInference done 1207/2712. Dataloading: 0.0024 s/iter. Inference: 0.2861 s/iter. Eval: 0.0004 s/iter. Total: 0.2891 s/iter. ETA=0:07:15\n",
      "\u001b[32m[04/01 18:23:17 d2.evaluation.evaluator]: \u001b[0mInference done 1224/2712. Dataloading: 0.0024 s/iter. Inference: 0.2862 s/iter. Eval: 0.0005 s/iter. Total: 0.2893 s/iter. ETA=0:07:10\n",
      "\u001b[32m[04/01 18:23:22 d2.evaluation.evaluator]: \u001b[0mInference done 1240/2712. Dataloading: 0.0024 s/iter. Inference: 0.2865 s/iter. Eval: 0.0005 s/iter. Total: 0.2896 s/iter. ETA=0:07:06\n",
      "\u001b[32m[04/01 18:23:27 d2.evaluation.evaluator]: \u001b[0mInference done 1258/2712. Dataloading: 0.0024 s/iter. Inference: 0.2864 s/iter. Eval: 0.0005 s/iter. Total: 0.2895 s/iter. ETA=0:07:00\n",
      "\u001b[32m[04/01 18:23:32 d2.evaluation.evaluator]: \u001b[0mInference done 1276/2712. Dataloading: 0.0024 s/iter. Inference: 0.2863 s/iter. Eval: 0.0005 s/iter. Total: 0.2894 s/iter. ETA=0:06:55\n",
      "\u001b[32m[04/01 18:23:37 d2.evaluation.evaluator]: \u001b[0mInference done 1293/2712. Dataloading: 0.0024 s/iter. Inference: 0.2864 s/iter. Eval: 0.0005 s/iter. Total: 0.2895 s/iter. ETA=0:06:50\n",
      "\u001b[32m[04/01 18:23:43 d2.evaluation.evaluator]: \u001b[0mInference done 1311/2712. Dataloading: 0.0024 s/iter. Inference: 0.2864 s/iter. Eval: 0.0005 s/iter. Total: 0.2894 s/iter. ETA=0:06:45\n",
      "\u001b[32m[04/01 18:23:48 d2.evaluation.evaluator]: \u001b[0mInference done 1329/2712. Dataloading: 0.0024 s/iter. Inference: 0.2864 s/iter. Eval: 0.0005 s/iter. Total: 0.2894 s/iter. ETA=0:06:40\n",
      "\u001b[32m[04/01 18:23:53 d2.evaluation.evaluator]: \u001b[0mInference done 1347/2712. Dataloading: 0.0024 s/iter. Inference: 0.2864 s/iter. Eval: 0.0005 s/iter. Total: 0.2895 s/iter. ETA=0:06:35\n",
      "\u001b[32m[04/01 18:23:58 d2.evaluation.evaluator]: \u001b[0mInference done 1365/2712. Dataloading: 0.0024 s/iter. Inference: 0.2865 s/iter. Eval: 0.0005 s/iter. Total: 0.2896 s/iter. ETA=0:06:30\n",
      "\u001b[32m[04/01 18:24:04 d2.evaluation.evaluator]: \u001b[0mInference done 1382/2712. Dataloading: 0.0024 s/iter. Inference: 0.2868 s/iter. Eval: 0.0005 s/iter. Total: 0.2898 s/iter. ETA=0:06:25\n",
      "\u001b[32m[04/01 18:24:09 d2.evaluation.evaluator]: \u001b[0mInference done 1399/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0005 s/iter. Total: 0.2900 s/iter. ETA=0:06:20\n",
      "\u001b[32m[04/01 18:24:14 d2.evaluation.evaluator]: \u001b[0mInference done 1417/2712. Dataloading: 0.0024 s/iter. Inference: 0.2868 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:06:15\n",
      "\u001b[32m[04/01 18:24:19 d2.evaluation.evaluator]: \u001b[0mInference done 1436/2712. Dataloading: 0.0024 s/iter. Inference: 0.2866 s/iter. Eval: 0.0006 s/iter. Total: 0.2897 s/iter. ETA=0:06:09\n",
      "\u001b[32m[04/01 18:24:24 d2.evaluation.evaluator]: \u001b[0mInference done 1453/2712. Dataloading: 0.0024 s/iter. Inference: 0.2867 s/iter. Eval: 0.0005 s/iter. Total: 0.2898 s/iter. ETA=0:06:04\n",
      "\u001b[32m[04/01 18:24:29 d2.evaluation.evaluator]: \u001b[0mInference done 1471/2712. Dataloading: 0.0024 s/iter. Inference: 0.2866 s/iter. Eval: 0.0005 s/iter. Total: 0.2897 s/iter. ETA=0:05:59\n",
      "\u001b[32m[04/01 18:24:34 d2.evaluation.evaluator]: \u001b[0mInference done 1488/2712. Dataloading: 0.0024 s/iter. Inference: 0.2867 s/iter. Eval: 0.0005 s/iter. Total: 0.2898 s/iter. ETA=0:05:54\n",
      "\u001b[32m[04/01 18:24:40 d2.evaluation.evaluator]: \u001b[0mInference done 1505/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0005 s/iter. Total: 0.2899 s/iter. ETA=0:05:49\n",
      "\u001b[32m[04/01 18:24:45 d2.evaluation.evaluator]: \u001b[0mInference done 1523/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0005 s/iter. Total: 0.2899 s/iter. ETA=0:05:44\n",
      "\u001b[32m[04/01 18:24:50 d2.evaluation.evaluator]: \u001b[0mInference done 1540/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0005 s/iter. Total: 0.2900 s/iter. ETA=0:05:39\n",
      "\u001b[32m[04/01 18:24:55 d2.evaluation.evaluator]: \u001b[0mInference done 1558/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0005 s/iter. Total: 0.2900 s/iter. ETA=0:05:34\n",
      "\u001b[32m[04/01 18:25:00 d2.evaluation.evaluator]: \u001b[0mInference done 1576/2712. Dataloading: 0.0024 s/iter. Inference: 0.2868 s/iter. Eval: 0.0005 s/iter. Total: 0.2900 s/iter. ETA=0:05:29\n",
      "\u001b[32m[04/01 18:25:05 d2.evaluation.evaluator]: \u001b[0mInference done 1594/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0005 s/iter. Total: 0.2900 s/iter. ETA=0:05:24\n",
      "\u001b[32m[04/01 18:25:11 d2.evaluation.evaluator]: \u001b[0mInference done 1612/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0005 s/iter. Total: 0.2899 s/iter. ETA=0:05:18\n",
      "\u001b[32m[04/01 18:25:16 d2.evaluation.evaluator]: \u001b[0mInference done 1629/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:05:14\n",
      "\u001b[32m[04/01 18:25:21 d2.evaluation.evaluator]: \u001b[0mInference done 1647/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:05:08\n",
      "\u001b[32m[04/01 18:25:26 d2.evaluation.evaluator]: \u001b[0mInference done 1664/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:05:03\n",
      "\u001b[32m[04/01 18:25:31 d2.evaluation.evaluator]: \u001b[0mInference done 1680/2712. Dataloading: 0.0025 s/iter. Inference: 0.2871 s/iter. Eval: 0.0006 s/iter. Total: 0.2903 s/iter. ETA=0:04:59\n",
      "\u001b[32m[04/01 18:25:36 d2.evaluation.evaluator]: \u001b[0mInference done 1698/2712. Dataloading: 0.0025 s/iter. Inference: 0.2871 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:04:54\n",
      "\u001b[32m[04/01 18:25:41 d2.evaluation.evaluator]: \u001b[0mInference done 1716/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:04:49\n",
      "\u001b[32m[04/01 18:25:46 d2.evaluation.evaluator]: \u001b[0mInference done 1734/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:04:43\n",
      "\u001b[32m[04/01 18:25:51 d2.evaluation.evaluator]: \u001b[0mInference done 1752/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:04:38\n",
      "\u001b[32m[04/01 18:25:57 d2.evaluation.evaluator]: \u001b[0mInference done 1770/2712. Dataloading: 0.0024 s/iter. Inference: 0.2871 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:04:33\n",
      "\u001b[32m[04/01 18:26:02 d2.evaluation.evaluator]: \u001b[0mInference done 1788/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:04:28\n",
      "\u001b[32m[04/01 18:26:07 d2.evaluation.evaluator]: \u001b[0mInference done 1806/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:04:22\n",
      "\u001b[32m[04/01 18:26:12 d2.evaluation.evaluator]: \u001b[0mInference done 1824/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:04:17\n",
      "\u001b[32m[04/01 18:26:18 d2.evaluation.evaluator]: \u001b[0mInference done 1841/2712. Dataloading: 0.0024 s/iter. Inference: 0.2872 s/iter. Eval: 0.0006 s/iter. Total: 0.2903 s/iter. ETA=0:04:12\n",
      "\u001b[32m[04/01 18:26:23 d2.evaluation.evaluator]: \u001b[0mInference done 1859/2712. Dataloading: 0.0023 s/iter. Inference: 0.2872 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:04:07\n",
      "\u001b[32m[04/01 18:26:28 d2.evaluation.evaluator]: \u001b[0mInference done 1877/2712. Dataloading: 0.0023 s/iter. Inference: 0.2871 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:04:02\n",
      "\u001b[32m[04/01 18:26:33 d2.evaluation.evaluator]: \u001b[0mInference done 1895/2712. Dataloading: 0.0024 s/iter. Inference: 0.2871 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:03:57\n",
      "\u001b[32m[04/01 18:26:38 d2.evaluation.evaluator]: \u001b[0mInference done 1913/2712. Dataloading: 0.0024 s/iter. Inference: 0.2872 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:03:51\n",
      "\u001b[32m[04/01 18:26:44 d2.evaluation.evaluator]: \u001b[0mInference done 1932/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:03:46\n",
      "\u001b[32m[04/01 18:26:49 d2.evaluation.evaluator]: \u001b[0mInference done 1950/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:03:41\n",
      "\u001b[32m[04/01 18:26:54 d2.evaluation.evaluator]: \u001b[0mInference done 1968/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:03:35\n",
      "\u001b[32m[04/01 18:26:59 d2.evaluation.evaluator]: \u001b[0mInference done 1986/2712. Dataloading: 0.0023 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:03:30\n",
      "\u001b[32m[04/01 18:27:04 d2.evaluation.evaluator]: \u001b[0mInference done 2004/2712. Dataloading: 0.0023 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:03:25\n",
      "\u001b[32m[04/01 18:27:09 d2.evaluation.evaluator]: \u001b[0mInference done 2021/2712. Dataloading: 0.0023 s/iter. Inference: 0.2871 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:03:20\n",
      "\u001b[32m[04/01 18:27:15 d2.evaluation.evaluator]: \u001b[0mInference done 2039/2712. Dataloading: 0.0023 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:03:15\n",
      "\u001b[32m[04/01 18:27:20 d2.evaluation.evaluator]: \u001b[0mInference done 2057/2712. Dataloading: 0.0023 s/iter. Inference: 0.2870 s/iter. Eval: 0.0005 s/iter. Total: 0.2900 s/iter. ETA=0:03:09\n",
      "\u001b[32m[04/01 18:27:25 d2.evaluation.evaluator]: \u001b[0mInference done 2075/2712. Dataloading: 0.0023 s/iter. Inference: 0.2870 s/iter. Eval: 0.0005 s/iter. Total: 0.2900 s/iter. ETA=0:03:04\n",
      "\u001b[32m[04/01 18:27:30 d2.evaluation.evaluator]: \u001b[0mInference done 2093/2712. Dataloading: 0.0023 s/iter. Inference: 0.2870 s/iter. Eval: 0.0005 s/iter. Total: 0.2900 s/iter. ETA=0:02:59\n",
      "\u001b[32m[04/01 18:27:35 d2.evaluation.evaluator]: \u001b[0mInference done 2111/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0005 s/iter. Total: 0.2900 s/iter. ETA=0:02:54\n",
      "\u001b[32m[04/01 18:27:41 d2.evaluation.evaluator]: \u001b[0mInference done 2129/2712. Dataloading: 0.0023 s/iter. Inference: 0.2870 s/iter. Eval: 0.0005 s/iter. Total: 0.2900 s/iter. ETA=0:02:49\n",
      "\u001b[32m[04/01 18:27:46 d2.evaluation.evaluator]: \u001b[0mInference done 2146/2712. Dataloading: 0.0023 s/iter. Inference: 0.2871 s/iter. Eval: 0.0005 s/iter. Total: 0.2901 s/iter. ETA=0:02:44\n",
      "\u001b[32m[04/01 18:27:51 d2.evaluation.evaluator]: \u001b[0mInference done 2163/2712. Dataloading: 0.0023 s/iter. Inference: 0.2872 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:02:39\n",
      "\u001b[32m[04/01 18:27:56 d2.evaluation.evaluator]: \u001b[0mInference done 2178/2712. Dataloading: 0.0023 s/iter. Inference: 0.2875 s/iter. Eval: 0.0006 s/iter. Total: 0.2905 s/iter. ETA=0:02:35\n",
      "\u001b[32m[04/01 18:28:01 d2.evaluation.evaluator]: \u001b[0mInference done 2195/2712. Dataloading: 0.0023 s/iter. Inference: 0.2875 s/iter. Eval: 0.0006 s/iter. Total: 0.2906 s/iter. ETA=0:02:30\n",
      "\u001b[32m[04/01 18:28:06 d2.evaluation.evaluator]: \u001b[0mInference done 2214/2712. Dataloading: 0.0023 s/iter. Inference: 0.2875 s/iter. Eval: 0.0006 s/iter. Total: 0.2905 s/iter. ETA=0:02:24\n",
      "\u001b[32m[04/01 18:28:11 d2.evaluation.evaluator]: \u001b[0mInference done 2231/2712. Dataloading: 0.0023 s/iter. Inference: 0.2875 s/iter. Eval: 0.0006 s/iter. Total: 0.2905 s/iter. ETA=0:02:19\n",
      "\u001b[32m[04/01 18:28:17 d2.evaluation.evaluator]: \u001b[0mInference done 2249/2712. Dataloading: 0.0023 s/iter. Inference: 0.2875 s/iter. Eval: 0.0006 s/iter. Total: 0.2906 s/iter. ETA=0:02:14\n",
      "\u001b[32m[04/01 18:28:22 d2.evaluation.evaluator]: \u001b[0mInference done 2267/2712. Dataloading: 0.0023 s/iter. Inference: 0.2874 s/iter. Eval: 0.0006 s/iter. Total: 0.2905 s/iter. ETA=0:02:09\n",
      "\u001b[32m[04/01 18:28:27 d2.evaluation.evaluator]: \u001b[0mInference done 2285/2712. Dataloading: 0.0023 s/iter. Inference: 0.2874 s/iter. Eval: 0.0006 s/iter. Total: 0.2905 s/iter. ETA=0:02:04\n",
      "\u001b[32m[04/01 18:28:32 d2.evaluation.evaluator]: \u001b[0mInference done 2302/2712. Dataloading: 0.0024 s/iter. Inference: 0.2875 s/iter. Eval: 0.0006 s/iter. Total: 0.2906 s/iter. ETA=0:01:59\n",
      "\u001b[32m[04/01 18:28:37 d2.evaluation.evaluator]: \u001b[0mInference done 2320/2712. Dataloading: 0.0023 s/iter. Inference: 0.2874 s/iter. Eval: 0.0006 s/iter. Total: 0.2905 s/iter. ETA=0:01:53\n",
      "\u001b[32m[04/01 18:28:42 d2.evaluation.evaluator]: \u001b[0mInference done 2338/2712. Dataloading: 0.0023 s/iter. Inference: 0.2874 s/iter. Eval: 0.0006 s/iter. Total: 0.2904 s/iter. ETA=0:01:48\n",
      "\u001b[32m[04/01 18:28:47 d2.evaluation.evaluator]: \u001b[0mInference done 2355/2712. Dataloading: 0.0023 s/iter. Inference: 0.2875 s/iter. Eval: 0.0006 s/iter. Total: 0.2906 s/iter. ETA=0:01:43\n",
      "\u001b[32m[04/01 18:28:53 d2.evaluation.evaluator]: \u001b[0mInference done 2373/2712. Dataloading: 0.0023 s/iter. Inference: 0.2874 s/iter. Eval: 0.0006 s/iter. Total: 0.2905 s/iter. ETA=0:01:38\n",
      "\u001b[32m[04/01 18:28:58 d2.evaluation.evaluator]: \u001b[0mInference done 2391/2712. Dataloading: 0.0023 s/iter. Inference: 0.2874 s/iter. Eval: 0.0006 s/iter. Total: 0.2905 s/iter. ETA=0:01:33\n",
      "\u001b[32m[04/01 18:29:03 d2.evaluation.evaluator]: \u001b[0mInference done 2409/2712. Dataloading: 0.0023 s/iter. Inference: 0.2874 s/iter. Eval: 0.0006 s/iter. Total: 0.2904 s/iter. ETA=0:01:28\n",
      "\u001b[32m[04/01 18:29:08 d2.evaluation.evaluator]: \u001b[0mInference done 2427/2712. Dataloading: 0.0024 s/iter. Inference: 0.2873 s/iter. Eval: 0.0006 s/iter. Total: 0.2904 s/iter. ETA=0:01:22\n",
      "\u001b[32m[04/01 18:29:13 d2.evaluation.evaluator]: \u001b[0mInference done 2445/2712. Dataloading: 0.0024 s/iter. Inference: 0.2873 s/iter. Eval: 0.0006 s/iter. Total: 0.2904 s/iter. ETA=0:01:17\n",
      "\u001b[32m[04/01 18:29:18 d2.evaluation.evaluator]: \u001b[0mInference done 2463/2712. Dataloading: 0.0023 s/iter. Inference: 0.2872 s/iter. Eval: 0.0006 s/iter. Total: 0.2903 s/iter. ETA=0:01:12\n",
      "\u001b[32m[04/01 18:29:24 d2.evaluation.evaluator]: \u001b[0mInference done 2482/2712. Dataloading: 0.0024 s/iter. Inference: 0.2871 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:01:06\n",
      "\u001b[32m[04/01 18:29:29 d2.evaluation.evaluator]: \u001b[0mInference done 2500/2712. Dataloading: 0.0024 s/iter. Inference: 0.2871 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:01:01\n",
      "\u001b[32m[04/01 18:29:34 d2.evaluation.evaluator]: \u001b[0mInference done 2519/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:00:55\n",
      "\u001b[32m[04/01 18:29:39 d2.evaluation.evaluator]: \u001b[0mInference done 2537/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:00:50\n",
      "\u001b[32m[04/01 18:29:44 d2.evaluation.evaluator]: \u001b[0mInference done 2554/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:00:45\n",
      "\u001b[32m[04/01 18:29:49 d2.evaluation.evaluator]: \u001b[0mInference done 2571/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:00:40\n",
      "\u001b[32m[04/01 18:29:54 d2.evaluation.evaluator]: \u001b[0mInference done 2589/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:00:35\n",
      "\u001b[32m[04/01 18:29:59 d2.evaluation.evaluator]: \u001b[0mInference done 2607/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:00:30\n",
      "\u001b[32m[04/01 18:30:05 d2.evaluation.evaluator]: \u001b[0mInference done 2625/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:00:25\n",
      "\u001b[32m[04/01 18:30:10 d2.evaluation.evaluator]: \u001b[0mInference done 2643/2712. Dataloading: 0.0024 s/iter. Inference: 0.2868 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:00:20\n",
      "\u001b[32m[04/01 18:30:15 d2.evaluation.evaluator]: \u001b[0mInference done 2661/2712. Dataloading: 0.0024 s/iter. Inference: 0.2868 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:00:14\n",
      "\u001b[32m[04/01 18:30:20 d2.evaluation.evaluator]: \u001b[0mInference done 2679/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:00:09\n",
      "\u001b[32m[04/01 18:30:26 d2.evaluation.evaluator]: \u001b[0mInference done 2696/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:00:04\n",
      "\u001b[32m[04/01 18:30:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:13:05.401464 (0.290137 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/01 18:30:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:12:56 (0.286890 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/01 18:30:31 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/01 18:30:31 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[04/01 18:30:32 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.66s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/01 18:30:33 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/01 18:30:34 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 1.53 seconds.\n",
      "\u001b[32m[04/01 18:30:35 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/01 18:30:35 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.45 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.032\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.007\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.048\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.013\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.050\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.069\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.075\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.242\n",
      "\u001b[32m[04/01 18:30:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 1.356 | 3.231  | 0.668  | 0.227 | 1.384 | 4.840 |\n",
      "\u001b[32m[04/01 18:30:35 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP    | category   | AP    |\n",
      "|:-----------|:------|:-----------|:------|:-----------|:------|\n",
      "| Bus        | 0.007 | Bike       | 0.658 | Car        | 5.999 |\n",
      "| Pedestrian | 0.064 | Truck      | 0.053 |            |       |\n",
      "\u001b[32m[04/01 18:30:35 d2.engine.defaults]: \u001b[0mEvaluation results for fisheye8k_val in csv format:\n",
      "\u001b[32m[04/01 18:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/01 18:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/01 18:30:35 d2.evaluation.testing]: \u001b[0mcopypaste: 1.3563,3.2308,0.6679,0.2274,1.3840,4.8395\n",
      "\u001b[32m[04/01 18:30:35 d2.utils.events]: \u001b[0m eta: 0:07:03  iter: 99  total_loss: 1.495  loss_cls: 0.6561  loss_box_reg: 0.5301  loss_rpn_cls: 0.0866  loss_rpn_loc: 0.2433    time: 2.0005  last_time: 1.4893  data_time: 0.6670  last_data_time: 0.5648   lr: 8.2668e-05  max_mem: 45332M\n",
      "\u001b[32m[04/01 18:31:15 d2.utils.events]: \u001b[0m eta: 0:06:24  iter: 119  total_loss: 1.481  loss_cls: 0.6268  loss_box_reg: 0.5546  loss_rpn_cls: 0.0817  loss_rpn_loc: 0.2228    time: 2.0032  last_time: 2.4987  data_time: 0.6442  last_data_time: 1.0114   lr: 9.9318e-05  max_mem: 45332M\n",
      "\u001b[32m[04/01 18:31:55 d2.utils.events]: \u001b[0m eta: 0:05:38  iter: 139  total_loss: 1.483  loss_cls: 0.6131  loss_box_reg: 0.5743  loss_rpn_cls: 0.07591  loss_rpn_loc: 0.2275    time: 2.0001  last_time: 1.6218  data_time: 0.6446  last_data_time: 0.4660   lr: 0.00011597  max_mem: 45332M\n",
      "\u001b[32m[04/01 18:32:34 d2.utils.events]: \u001b[0m eta: 0:04:55  iter: 159  total_loss: 1.485  loss_cls: 0.6  loss_box_reg: 0.5943  loss_rpn_cls: 0.07381  loss_rpn_loc: 0.2277    time: 1.9933  last_time: 2.2162  data_time: 0.5869  last_data_time: 0.7973   lr: 0.00013262  max_mem: 45332M\n",
      "\u001b[32m[04/01 18:33:13 d2.utils.events]: \u001b[0m eta: 0:04:13  iter: 179  total_loss: 1.507  loss_cls: 0.5959  loss_box_reg: 0.6003  loss_rpn_cls: 0.06985  loss_rpn_loc: 0.2281    time: 1.9902  last_time: 2.1357  data_time: 0.6079  last_data_time: 0.4368   lr: 0.00014927  max_mem: 45332M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/01 18:33:53 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/01 18:33:53 d2.data.datasets.coco]: \u001b[0mLoaded 2712 images in COCO format from /workspace/FishEye8k/dataset/Fisheye8K_all_including_train/test/test.json\n",
      "\u001b[32m[04/01 18:33:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[04/01 18:33:54 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[04/01 18:33:54 d2.data.common]: \u001b[0mSerializing 2712 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/01 18:33:54 d2.data.common]: \u001b[0mSerialized dataset takes 2.01 MiB\n",
      "\u001b[32m[04/01 18:33:54 d2.evaluation.evaluator]: \u001b[0mStart inference on 2712 batches\n",
      "\u001b[32m[04/01 18:34:02 d2.evaluation.evaluator]: \u001b[0mInference done 11/2712. Dataloading: 0.0009 s/iter. Inference: 0.2648 s/iter. Eval: 0.0003 s/iter. Total: 0.2660 s/iter. ETA=0:11:58\n",
      "\u001b[32m[04/01 18:34:08 d2.evaluation.evaluator]: \u001b[0mInference done 29/2712. Dataloading: 0.0012 s/iter. Inference: 0.2812 s/iter. Eval: 0.0006 s/iter. Total: 0.2832 s/iter. ETA=0:12:39\n",
      "\u001b[32m[04/01 18:34:13 d2.evaluation.evaluator]: \u001b[0mInference done 49/2712. Dataloading: 0.0012 s/iter. Inference: 0.2730 s/iter. Eval: 0.0005 s/iter. Total: 0.2749 s/iter. ETA=0:12:12\n",
      "\u001b[32m[04/01 18:34:18 d2.evaluation.evaluator]: \u001b[0mInference done 67/2712. Dataloading: 0.0013 s/iter. Inference: 0.2753 s/iter. Eval: 0.0005 s/iter. Total: 0.2772 s/iter. ETA=0:12:13\n",
      "\u001b[32m[04/01 18:34:23 d2.evaluation.evaluator]: \u001b[0mInference done 86/2712. Dataloading: 0.0031 s/iter. Inference: 0.2728 s/iter. Eval: 0.0005 s/iter. Total: 0.2765 s/iter. ETA=0:12:05\n",
      "\u001b[32m[04/01 18:34:28 d2.evaluation.evaluator]: \u001b[0mInference done 103/2712. Dataloading: 0.0028 s/iter. Inference: 0.2772 s/iter. Eval: 0.0005 s/iter. Total: 0.2805 s/iter. ETA=0:12:11\n",
      "\u001b[32m[04/01 18:34:34 d2.evaluation.evaluator]: \u001b[0mInference done 122/2712. Dataloading: 0.0025 s/iter. Inference: 0.2763 s/iter. Eval: 0.0004 s/iter. Total: 0.2794 s/iter. ETA=0:12:03\n",
      "\u001b[32m[04/01 18:34:39 d2.evaluation.evaluator]: \u001b[0mInference done 141/2712. Dataloading: 0.0024 s/iter. Inference: 0.2756 s/iter. Eval: 0.0004 s/iter. Total: 0.2785 s/iter. ETA=0:11:56\n",
      "\u001b[32m[04/01 18:34:44 d2.evaluation.evaluator]: \u001b[0mInference done 160/2712. Dataloading: 0.0027 s/iter. Inference: 0.2734 s/iter. Eval: 0.0004 s/iter. Total: 0.2767 s/iter. ETA=0:11:46\n",
      "\u001b[32m[04/01 18:34:49 d2.evaluation.evaluator]: \u001b[0mInference done 178/2712. Dataloading: 0.0030 s/iter. Inference: 0.2733 s/iter. Eval: 0.0004 s/iter. Total: 0.2768 s/iter. ETA=0:11:41\n",
      "\u001b[32m[04/01 18:34:54 d2.evaluation.evaluator]: \u001b[0mInference done 197/2712. Dataloading: 0.0036 s/iter. Inference: 0.2714 s/iter. Eval: 0.0014 s/iter. Total: 0.2765 s/iter. ETA=0:11:35\n",
      "\u001b[32m[04/01 18:34:59 d2.evaluation.evaluator]: \u001b[0mInference done 216/2712. Dataloading: 0.0034 s/iter. Inference: 0.2709 s/iter. Eval: 0.0013 s/iter. Total: 0.2758 s/iter. ETA=0:11:28\n",
      "\u001b[32m[04/01 18:35:04 d2.evaluation.evaluator]: \u001b[0mInference done 235/2712. Dataloading: 0.0032 s/iter. Inference: 0.2705 s/iter. Eval: 0.0013 s/iter. Total: 0.2752 s/iter. ETA=0:11:21\n",
      "\u001b[32m[04/01 18:35:09 d2.evaluation.evaluator]: \u001b[0mInference done 254/2712. Dataloading: 0.0034 s/iter. Inference: 0.2699 s/iter. Eval: 0.0012 s/iter. Total: 0.2746 s/iter. ETA=0:11:15\n",
      "\u001b[32m[04/01 18:35:14 d2.evaluation.evaluator]: \u001b[0mInference done 273/2712. Dataloading: 0.0035 s/iter. Inference: 0.2694 s/iter. Eval: 0.0011 s/iter. Total: 0.2742 s/iter. ETA=0:11:08\n",
      "\u001b[32m[04/01 18:35:20 d2.evaluation.evaluator]: \u001b[0mInference done 292/2712. Dataloading: 0.0034 s/iter. Inference: 0.2695 s/iter. Eval: 0.0011 s/iter. Total: 0.2742 s/iter. ETA=0:11:03\n",
      "\u001b[32m[04/01 18:35:25 d2.evaluation.evaluator]: \u001b[0mInference done 310/2712. Dataloading: 0.0033 s/iter. Inference: 0.2699 s/iter. Eval: 0.0010 s/iter. Total: 0.2744 s/iter. ETA=0:10:59\n",
      "\u001b[32m[04/01 18:35:30 d2.evaluation.evaluator]: \u001b[0mInference done 328/2712. Dataloading: 0.0032 s/iter. Inference: 0.2709 s/iter. Eval: 0.0010 s/iter. Total: 0.2752 s/iter. ETA=0:10:56\n",
      "\u001b[32m[04/01 18:35:35 d2.evaluation.evaluator]: \u001b[0mInference done 348/2712. Dataloading: 0.0030 s/iter. Inference: 0.2705 s/iter. Eval: 0.0010 s/iter. Total: 0.2746 s/iter. ETA=0:10:49\n",
      "\u001b[32m[04/01 18:35:40 d2.evaluation.evaluator]: \u001b[0mInference done 366/2712. Dataloading: 0.0029 s/iter. Inference: 0.2707 s/iter. Eval: 0.0009 s/iter. Total: 0.2748 s/iter. ETA=0:10:44\n",
      "\u001b[32m[04/01 18:35:45 d2.evaluation.evaluator]: \u001b[0mInference done 385/2712. Dataloading: 0.0031 s/iter. Inference: 0.2706 s/iter. Eval: 0.0009 s/iter. Total: 0.2747 s/iter. ETA=0:10:39\n",
      "\u001b[32m[04/01 18:35:50 d2.evaluation.evaluator]: \u001b[0mInference done 404/2712. Dataloading: 0.0030 s/iter. Inference: 0.2707 s/iter. Eval: 0.0009 s/iter. Total: 0.2747 s/iter. ETA=0:10:33\n",
      "\u001b[32m[04/01 18:35:56 d2.evaluation.evaluator]: \u001b[0mInference done 423/2712. Dataloading: 0.0029 s/iter. Inference: 0.2707 s/iter. Eval: 0.0009 s/iter. Total: 0.2746 s/iter. ETA=0:10:28\n",
      "\u001b[32m[04/01 18:36:01 d2.evaluation.evaluator]: \u001b[0mInference done 441/2712. Dataloading: 0.0028 s/iter. Inference: 0.2712 s/iter. Eval: 0.0008 s/iter. Total: 0.2750 s/iter. ETA=0:10:24\n",
      "\u001b[32m[04/01 18:36:06 d2.evaluation.evaluator]: \u001b[0mInference done 460/2712. Dataloading: 0.0028 s/iter. Inference: 0.2714 s/iter. Eval: 0.0008 s/iter. Total: 0.2752 s/iter. ETA=0:10:19\n",
      "\u001b[32m[04/01 18:36:11 d2.evaluation.evaluator]: \u001b[0mInference done 480/2712. Dataloading: 0.0027 s/iter. Inference: 0.2711 s/iter. Eval: 0.0008 s/iter. Total: 0.2747 s/iter. ETA=0:10:13\n",
      "\u001b[32m[04/01 18:36:16 d2.evaluation.evaluator]: \u001b[0mInference done 499/2712. Dataloading: 0.0026 s/iter. Inference: 0.2709 s/iter. Eval: 0.0008 s/iter. Total: 0.2744 s/iter. ETA=0:10:07\n",
      "\u001b[32m[04/01 18:36:22 d2.evaluation.evaluator]: \u001b[0mInference done 517/2712. Dataloading: 0.0026 s/iter. Inference: 0.2713 s/iter. Eval: 0.0008 s/iter. Total: 0.2748 s/iter. ETA=0:10:03\n",
      "\u001b[32m[04/01 18:36:27 d2.evaluation.evaluator]: \u001b[0mInference done 535/2712. Dataloading: 0.0027 s/iter. Inference: 0.2713 s/iter. Eval: 0.0008 s/iter. Total: 0.2749 s/iter. ETA=0:09:58\n",
      "\u001b[32m[04/01 18:36:32 d2.evaluation.evaluator]: \u001b[0mInference done 553/2712. Dataloading: 0.0027 s/iter. Inference: 0.2716 s/iter. Eval: 0.0008 s/iter. Total: 0.2752 s/iter. ETA=0:09:54\n",
      "\u001b[32m[04/01 18:36:37 d2.evaluation.evaluator]: \u001b[0mInference done 572/2712. Dataloading: 0.0026 s/iter. Inference: 0.2718 s/iter. Eval: 0.0007 s/iter. Total: 0.2753 s/iter. ETA=0:09:49\n",
      "\u001b[32m[04/01 18:36:42 d2.evaluation.evaluator]: \u001b[0mInference done 591/2712. Dataloading: 0.0027 s/iter. Inference: 0.2717 s/iter. Eval: 0.0007 s/iter. Total: 0.2752 s/iter. ETA=0:09:43\n",
      "\u001b[32m[04/01 18:36:47 d2.evaluation.evaluator]: \u001b[0mInference done 610/2712. Dataloading: 0.0027 s/iter. Inference: 0.2715 s/iter. Eval: 0.0007 s/iter. Total: 0.2750 s/iter. ETA=0:09:38\n",
      "\u001b[32m[04/01 18:36:52 d2.evaluation.evaluator]: \u001b[0mInference done 629/2712. Dataloading: 0.0026 s/iter. Inference: 0.2714 s/iter. Eval: 0.0007 s/iter. Total: 0.2748 s/iter. ETA=0:09:32\n",
      "\u001b[32m[04/01 18:36:58 d2.evaluation.evaluator]: \u001b[0mInference done 648/2712. Dataloading: 0.0027 s/iter. Inference: 0.2716 s/iter. Eval: 0.0007 s/iter. Total: 0.2751 s/iter. ETA=0:09:27\n",
      "\u001b[32m[04/01 18:37:03 d2.evaluation.evaluator]: \u001b[0mInference done 665/2712. Dataloading: 0.0027 s/iter. Inference: 0.2724 s/iter. Eval: 0.0007 s/iter. Total: 0.2759 s/iter. ETA=0:09:24\n",
      "\u001b[32m[04/01 18:37:08 d2.evaluation.evaluator]: \u001b[0mInference done 684/2712. Dataloading: 0.0026 s/iter. Inference: 0.2722 s/iter. Eval: 0.0007 s/iter. Total: 0.2757 s/iter. ETA=0:09:19\n",
      "\u001b[32m[04/01 18:37:13 d2.evaluation.evaluator]: \u001b[0mInference done 703/2712. Dataloading: 0.0026 s/iter. Inference: 0.2721 s/iter. Eval: 0.0007 s/iter. Total: 0.2755 s/iter. ETA=0:09:13\n",
      "\u001b[32m[04/01 18:37:18 d2.evaluation.evaluator]: \u001b[0mInference done 722/2712. Dataloading: 0.0027 s/iter. Inference: 0.2718 s/iter. Eval: 0.0007 s/iter. Total: 0.2753 s/iter. ETA=0:09:07\n",
      "\u001b[32m[04/01 18:37:23 d2.evaluation.evaluator]: \u001b[0mInference done 740/2712. Dataloading: 0.0026 s/iter. Inference: 0.2721 s/iter. Eval: 0.0007 s/iter. Total: 0.2755 s/iter. ETA=0:09:03\n",
      "\u001b[32m[04/01 18:37:28 d2.evaluation.evaluator]: \u001b[0mInference done 758/2712. Dataloading: 0.0026 s/iter. Inference: 0.2722 s/iter. Eval: 0.0007 s/iter. Total: 0.2756 s/iter. ETA=0:08:58\n",
      "\u001b[32m[04/01 18:37:33 d2.evaluation.evaluator]: \u001b[0mInference done 777/2712. Dataloading: 0.0026 s/iter. Inference: 0.2721 s/iter. Eval: 0.0006 s/iter. Total: 0.2754 s/iter. ETA=0:08:52\n",
      "\u001b[32m[04/01 18:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 796/2712. Dataloading: 0.0025 s/iter. Inference: 0.2719 s/iter. Eval: 0.0006 s/iter. Total: 0.2752 s/iter. ETA=0:08:47\n",
      "\u001b[32m[04/01 18:37:44 d2.evaluation.evaluator]: \u001b[0mInference done 814/2712. Dataloading: 0.0025 s/iter. Inference: 0.2720 s/iter. Eval: 0.0006 s/iter. Total: 0.2753 s/iter. ETA=0:08:42\n",
      "\u001b[32m[04/01 18:37:49 d2.evaluation.evaluator]: \u001b[0mInference done 833/2712. Dataloading: 0.0026 s/iter. Inference: 0.2718 s/iter. Eval: 0.0006 s/iter. Total: 0.2751 s/iter. ETA=0:08:36\n",
      "\u001b[32m[04/01 18:37:54 d2.evaluation.evaluator]: \u001b[0mInference done 852/2712. Dataloading: 0.0025 s/iter. Inference: 0.2718 s/iter. Eval: 0.0006 s/iter. Total: 0.2751 s/iter. ETA=0:08:31\n",
      "\u001b[32m[04/01 18:37:59 d2.evaluation.evaluator]: \u001b[0mInference done 871/2712. Dataloading: 0.0025 s/iter. Inference: 0.2713 s/iter. Eval: 0.0010 s/iter. Total: 0.2749 s/iter. ETA=0:08:26\n",
      "\u001b[32m[04/01 18:38:04 d2.evaluation.evaluator]: \u001b[0mInference done 888/2712. Dataloading: 0.0026 s/iter. Inference: 0.2720 s/iter. Eval: 0.0010 s/iter. Total: 0.2756 s/iter. ETA=0:08:22\n",
      "\u001b[32m[04/01 18:38:09 d2.evaluation.evaluator]: \u001b[0mInference done 906/2712. Dataloading: 0.0025 s/iter. Inference: 0.2722 s/iter. Eval: 0.0010 s/iter. Total: 0.2758 s/iter. ETA=0:08:18\n",
      "\u001b[32m[04/01 18:38:14 d2.evaluation.evaluator]: \u001b[0mInference done 925/2712. Dataloading: 0.0025 s/iter. Inference: 0.2720 s/iter. Eval: 0.0010 s/iter. Total: 0.2756 s/iter. ETA=0:08:12\n",
      "\u001b[32m[04/01 18:38:19 d2.evaluation.evaluator]: \u001b[0mInference done 944/2712. Dataloading: 0.0026 s/iter. Inference: 0.2717 s/iter. Eval: 0.0010 s/iter. Total: 0.2754 s/iter. ETA=0:08:06\n",
      "\u001b[32m[04/01 18:38:24 d2.evaluation.evaluator]: \u001b[0mInference done 963/2712. Dataloading: 0.0025 s/iter. Inference: 0.2715 s/iter. Eval: 0.0010 s/iter. Total: 0.2751 s/iter. ETA=0:08:01\n",
      "\u001b[32m[04/01 18:38:30 d2.evaluation.evaluator]: \u001b[0mInference done 982/2712. Dataloading: 0.0025 s/iter. Inference: 0.2714 s/iter. Eval: 0.0010 s/iter. Total: 0.2750 s/iter. ETA=0:07:55\n",
      "\u001b[32m[04/01 18:38:35 d2.evaluation.evaluator]: \u001b[0mInference done 1000/2712. Dataloading: 0.0025 s/iter. Inference: 0.2718 s/iter. Eval: 0.0010 s/iter. Total: 0.2754 s/iter. ETA=0:07:51\n",
      "\u001b[32m[04/01 18:38:40 d2.evaluation.evaluator]: \u001b[0mInference done 1019/2712. Dataloading: 0.0025 s/iter. Inference: 0.2718 s/iter. Eval: 0.0010 s/iter. Total: 0.2753 s/iter. ETA=0:07:46\n",
      "\u001b[32m[04/01 18:38:45 d2.evaluation.evaluator]: \u001b[0mInference done 1038/2712. Dataloading: 0.0025 s/iter. Inference: 0.2719 s/iter. Eval: 0.0010 s/iter. Total: 0.2754 s/iter. ETA=0:07:41\n",
      "\u001b[32m[04/01 18:38:51 d2.evaluation.evaluator]: \u001b[0mInference done 1058/2712. Dataloading: 0.0024 s/iter. Inference: 0.2716 s/iter. Eval: 0.0010 s/iter. Total: 0.2751 s/iter. ETA=0:07:35\n",
      "\u001b[32m[04/01 18:38:56 d2.evaluation.evaluator]: \u001b[0mInference done 1076/2712. Dataloading: 0.0024 s/iter. Inference: 0.2718 s/iter. Eval: 0.0009 s/iter. Total: 0.2752 s/iter. ETA=0:07:30\n",
      "\u001b[32m[04/01 18:39:01 d2.evaluation.evaluator]: \u001b[0mInference done 1095/2712. Dataloading: 0.0024 s/iter. Inference: 0.2718 s/iter. Eval: 0.0009 s/iter. Total: 0.2752 s/iter. ETA=0:07:25\n",
      "\u001b[32m[04/01 18:39:06 d2.evaluation.evaluator]: \u001b[0mInference done 1112/2712. Dataloading: 0.0024 s/iter. Inference: 0.2721 s/iter. Eval: 0.0009 s/iter. Total: 0.2755 s/iter. ETA=0:07:20\n",
      "\u001b[32m[04/01 18:39:11 d2.evaluation.evaluator]: \u001b[0mInference done 1131/2712. Dataloading: 0.0024 s/iter. Inference: 0.2721 s/iter. Eval: 0.0009 s/iter. Total: 0.2755 s/iter. ETA=0:07:15\n",
      "\u001b[32m[04/01 18:39:16 d2.evaluation.evaluator]: \u001b[0mInference done 1150/2712. Dataloading: 0.0024 s/iter. Inference: 0.2720 s/iter. Eval: 0.0009 s/iter. Total: 0.2755 s/iter. ETA=0:07:10\n",
      "\u001b[32m[04/01 18:39:21 d2.evaluation.evaluator]: \u001b[0mInference done 1167/2712. Dataloading: 0.0024 s/iter. Inference: 0.2725 s/iter. Eval: 0.0009 s/iter. Total: 0.2759 s/iter. ETA=0:07:06\n",
      "\u001b[32m[04/01 18:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 1186/2712. Dataloading: 0.0024 s/iter. Inference: 0.2724 s/iter. Eval: 0.0009 s/iter. Total: 0.2758 s/iter. ETA=0:07:00\n",
      "\u001b[32m[04/01 18:39:32 d2.evaluation.evaluator]: \u001b[0mInference done 1205/2712. Dataloading: 0.0024 s/iter. Inference: 0.2723 s/iter. Eval: 0.0009 s/iter. Total: 0.2757 s/iter. ETA=0:06:55\n",
      "\u001b[32m[04/01 18:39:37 d2.evaluation.evaluator]: \u001b[0mInference done 1223/2712. Dataloading: 0.0024 s/iter. Inference: 0.2724 s/iter. Eval: 0.0009 s/iter. Total: 0.2758 s/iter. ETA=0:06:50\n",
      "\u001b[32m[04/01 18:39:42 d2.evaluation.evaluator]: \u001b[0mInference done 1241/2712. Dataloading: 0.0024 s/iter. Inference: 0.2725 s/iter. Eval: 0.0009 s/iter. Total: 0.2759 s/iter. ETA=0:06:45\n",
      "\u001b[32m[04/01 18:39:47 d2.evaluation.evaluator]: \u001b[0mInference done 1259/2712. Dataloading: 0.0024 s/iter. Inference: 0.2727 s/iter. Eval: 0.0009 s/iter. Total: 0.2761 s/iter. ETA=0:06:41\n",
      "\u001b[32m[04/01 18:39:52 d2.evaluation.evaluator]: \u001b[0mInference done 1276/2712. Dataloading: 0.0024 s/iter. Inference: 0.2730 s/iter. Eval: 0.0009 s/iter. Total: 0.2763 s/iter. ETA=0:06:36\n",
      "\u001b[32m[04/01 18:39:57 d2.evaluation.evaluator]: \u001b[0mInference done 1292/2712. Dataloading: 0.0024 s/iter. Inference: 0.2736 s/iter. Eval: 0.0009 s/iter. Total: 0.2769 s/iter. ETA=0:06:33\n",
      "\u001b[32m[04/01 18:40:02 d2.evaluation.evaluator]: \u001b[0mInference done 1310/2712. Dataloading: 0.0024 s/iter. Inference: 0.2738 s/iter. Eval: 0.0009 s/iter. Total: 0.2771 s/iter. ETA=0:06:28\n",
      "\u001b[32m[04/01 18:40:08 d2.evaluation.evaluator]: \u001b[0mInference done 1329/2712. Dataloading: 0.0023 s/iter. Inference: 0.2737 s/iter. Eval: 0.0008 s/iter. Total: 0.2770 s/iter. ETA=0:06:23\n",
      "\u001b[32m[04/01 18:40:13 d2.evaluation.evaluator]: \u001b[0mInference done 1347/2712. Dataloading: 0.0023 s/iter. Inference: 0.2738 s/iter. Eval: 0.0008 s/iter. Total: 0.2770 s/iter. ETA=0:06:18\n",
      "\u001b[32m[04/01 18:40:18 d2.evaluation.evaluator]: \u001b[0mInference done 1363/2712. Dataloading: 0.0023 s/iter. Inference: 0.2742 s/iter. Eval: 0.0008 s/iter. Total: 0.2775 s/iter. ETA=0:06:14\n",
      "\u001b[32m[04/01 18:40:23 d2.evaluation.evaluator]: \u001b[0mInference done 1379/2712. Dataloading: 0.0023 s/iter. Inference: 0.2748 s/iter. Eval: 0.0008 s/iter. Total: 0.2781 s/iter. ETA=0:06:10\n",
      "\u001b[32m[04/01 18:40:28 d2.evaluation.evaluator]: \u001b[0mInference done 1397/2712. Dataloading: 0.0023 s/iter. Inference: 0.2749 s/iter. Eval: 0.0008 s/iter. Total: 0.2782 s/iter. ETA=0:06:05\n",
      "\u001b[32m[04/01 18:40:33 d2.evaluation.evaluator]: \u001b[0mInference done 1414/2712. Dataloading: 0.0023 s/iter. Inference: 0.2753 s/iter. Eval: 0.0008 s/iter. Total: 0.2786 s/iter. ETA=0:06:01\n",
      "\u001b[32m[04/01 18:40:38 d2.evaluation.evaluator]: \u001b[0mInference done 1429/2712. Dataloading: 0.0024 s/iter. Inference: 0.2758 s/iter. Eval: 0.0008 s/iter. Total: 0.2791 s/iter. ETA=0:05:58\n",
      "\u001b[32m[04/01 18:40:43 d2.evaluation.evaluator]: \u001b[0mInference done 1445/2712. Dataloading: 0.0024 s/iter. Inference: 0.2763 s/iter. Eval: 0.0008 s/iter. Total: 0.2796 s/iter. ETA=0:05:54\n",
      "\u001b[32m[04/01 18:40:49 d2.evaluation.evaluator]: \u001b[0mInference done 1461/2712. Dataloading: 0.0024 s/iter. Inference: 0.2768 s/iter. Eval: 0.0008 s/iter. Total: 0.2801 s/iter. ETA=0:05:50\n",
      "\u001b[32m[04/01 18:40:54 d2.evaluation.evaluator]: \u001b[0mInference done 1477/2712. Dataloading: 0.0024 s/iter. Inference: 0.2773 s/iter. Eval: 0.0008 s/iter. Total: 0.2806 s/iter. ETA=0:05:46\n",
      "\u001b[32m[04/01 18:40:59 d2.evaluation.evaluator]: \u001b[0mInference done 1492/2712. Dataloading: 0.0024 s/iter. Inference: 0.2781 s/iter. Eval: 0.0008 s/iter. Total: 0.2814 s/iter. ETA=0:05:43\n",
      "\u001b[32m[04/01 18:41:04 d2.evaluation.evaluator]: \u001b[0mInference done 1508/2712. Dataloading: 0.0024 s/iter. Inference: 0.2785 s/iter. Eval: 0.0008 s/iter. Total: 0.2818 s/iter. ETA=0:05:39\n",
      "\u001b[32m[04/01 18:41:09 d2.evaluation.evaluator]: \u001b[0mInference done 1526/2712. Dataloading: 0.0023 s/iter. Inference: 0.2785 s/iter. Eval: 0.0008 s/iter. Total: 0.2818 s/iter. ETA=0:05:34\n",
      "\u001b[32m[04/01 18:41:14 d2.evaluation.evaluator]: \u001b[0mInference done 1544/2712. Dataloading: 0.0023 s/iter. Inference: 0.2785 s/iter. Eval: 0.0008 s/iter. Total: 0.2817 s/iter. ETA=0:05:29\n",
      "\u001b[32m[04/01 18:41:19 d2.evaluation.evaluator]: \u001b[0mInference done 1563/2712. Dataloading: 0.0024 s/iter. Inference: 0.2782 s/iter. Eval: 0.0008 s/iter. Total: 0.2815 s/iter. ETA=0:05:23\n",
      "\u001b[32m[04/01 18:41:25 d2.evaluation.evaluator]: \u001b[0mInference done 1580/2712. Dataloading: 0.0024 s/iter. Inference: 0.2784 s/iter. Eval: 0.0008 s/iter. Total: 0.2817 s/iter. ETA=0:05:18\n",
      "\u001b[32m[04/01 18:41:30 d2.evaluation.evaluator]: \u001b[0mInference done 1599/2712. Dataloading: 0.0024 s/iter. Inference: 0.2783 s/iter. Eval: 0.0008 s/iter. Total: 0.2816 s/iter. ETA=0:05:13\n",
      "\u001b[32m[04/01 18:41:35 d2.evaluation.evaluator]: \u001b[0mInference done 1617/2712. Dataloading: 0.0024 s/iter. Inference: 0.2783 s/iter. Eval: 0.0008 s/iter. Total: 0.2816 s/iter. ETA=0:05:08\n",
      "\u001b[32m[04/01 18:41:40 d2.evaluation.evaluator]: \u001b[0mInference done 1636/2712. Dataloading: 0.0024 s/iter. Inference: 0.2782 s/iter. Eval: 0.0008 s/iter. Total: 0.2815 s/iter. ETA=0:05:02\n",
      "\u001b[32m[04/01 18:41:45 d2.evaluation.evaluator]: \u001b[0mInference done 1654/2712. Dataloading: 0.0024 s/iter. Inference: 0.2783 s/iter. Eval: 0.0008 s/iter. Total: 0.2816 s/iter. ETA=0:04:57\n",
      "\u001b[32m[04/01 18:41:50 d2.evaluation.evaluator]: \u001b[0mInference done 1672/2712. Dataloading: 0.0023 s/iter. Inference: 0.2782 s/iter. Eval: 0.0008 s/iter. Total: 0.2815 s/iter. ETA=0:04:52\n",
      "\u001b[32m[04/01 18:41:55 d2.evaluation.evaluator]: \u001b[0mInference done 1691/2712. Dataloading: 0.0024 s/iter. Inference: 0.2781 s/iter. Eval: 0.0008 s/iter. Total: 0.2814 s/iter. ETA=0:04:47\n",
      "\u001b[32m[04/01 18:42:01 d2.evaluation.evaluator]: \u001b[0mInference done 1709/2712. Dataloading: 0.0024 s/iter. Inference: 0.2781 s/iter. Eval: 0.0009 s/iter. Total: 0.2816 s/iter. ETA=0:04:42\n",
      "\u001b[32m[04/01 18:42:06 d2.evaluation.evaluator]: \u001b[0mInference done 1727/2712. Dataloading: 0.0023 s/iter. Inference: 0.2782 s/iter. Eval: 0.0009 s/iter. Total: 0.2816 s/iter. ETA=0:04:37\n",
      "\u001b[32m[04/01 18:42:11 d2.evaluation.evaluator]: \u001b[0mInference done 1744/2712. Dataloading: 0.0023 s/iter. Inference: 0.2785 s/iter. Eval: 0.0009 s/iter. Total: 0.2819 s/iter. ETA=0:04:32\n",
      "\u001b[32m[04/01 18:42:16 d2.evaluation.evaluator]: \u001b[0mInference done 1762/2712. Dataloading: 0.0023 s/iter. Inference: 0.2786 s/iter. Eval: 0.0009 s/iter. Total: 0.2820 s/iter. ETA=0:04:27\n",
      "\u001b[32m[04/01 18:42:22 d2.evaluation.evaluator]: \u001b[0mInference done 1781/2712. Dataloading: 0.0023 s/iter. Inference: 0.2786 s/iter. Eval: 0.0009 s/iter. Total: 0.2819 s/iter. ETA=0:04:22\n",
      "\u001b[32m[04/01 18:42:27 d2.evaluation.evaluator]: \u001b[0mInference done 1801/2712. Dataloading: 0.0023 s/iter. Inference: 0.2783 s/iter. Eval: 0.0009 s/iter. Total: 0.2817 s/iter. ETA=0:04:16\n",
      "\u001b[32m[04/01 18:42:32 d2.evaluation.evaluator]: \u001b[0mInference done 1819/2712. Dataloading: 0.0023 s/iter. Inference: 0.2784 s/iter. Eval: 0.0009 s/iter. Total: 0.2817 s/iter. ETA=0:04:11\n",
      "\u001b[32m[04/01 18:42:37 d2.evaluation.evaluator]: \u001b[0mInference done 1837/2712. Dataloading: 0.0023 s/iter. Inference: 0.2785 s/iter. Eval: 0.0009 s/iter. Total: 0.2818 s/iter. ETA=0:04:06\n",
      "\u001b[32m[04/01 18:42:42 d2.evaluation.evaluator]: \u001b[0mInference done 1855/2712. Dataloading: 0.0023 s/iter. Inference: 0.2784 s/iter. Eval: 0.0009 s/iter. Total: 0.2818 s/iter. ETA=0:04:01\n",
      "\u001b[32m[04/01 18:42:47 d2.evaluation.evaluator]: \u001b[0mInference done 1874/2712. Dataloading: 0.0023 s/iter. Inference: 0.2783 s/iter. Eval: 0.0009 s/iter. Total: 0.2816 s/iter. ETA=0:03:56\n",
      "\u001b[32m[04/01 18:42:52 d2.evaluation.evaluator]: \u001b[0mInference done 1890/2712. Dataloading: 0.0023 s/iter. Inference: 0.2786 s/iter. Eval: 0.0009 s/iter. Total: 0.2819 s/iter. ETA=0:03:51\n",
      "\u001b[32m[04/01 18:42:58 d2.evaluation.evaluator]: \u001b[0mInference done 1909/2712. Dataloading: 0.0023 s/iter. Inference: 0.2786 s/iter. Eval: 0.0009 s/iter. Total: 0.2819 s/iter. ETA=0:03:46\n",
      "\u001b[32m[04/01 18:43:03 d2.evaluation.evaluator]: \u001b[0mInference done 1927/2712. Dataloading: 0.0023 s/iter. Inference: 0.2786 s/iter. Eval: 0.0009 s/iter. Total: 0.2819 s/iter. ETA=0:03:41\n",
      "\u001b[32m[04/01 18:43:08 d2.evaluation.evaluator]: \u001b[0mInference done 1944/2712. Dataloading: 0.0023 s/iter. Inference: 0.2788 s/iter. Eval: 0.0009 s/iter. Total: 0.2821 s/iter. ETA=0:03:36\n",
      "\u001b[32m[04/01 18:43:13 d2.evaluation.evaluator]: \u001b[0mInference done 1962/2712. Dataloading: 0.0023 s/iter. Inference: 0.2788 s/iter. Eval: 0.0009 s/iter. Total: 0.2822 s/iter. ETA=0:03:31\n",
      "\u001b[32m[04/01 18:43:18 d2.evaluation.evaluator]: \u001b[0mInference done 1982/2712. Dataloading: 0.0023 s/iter. Inference: 0.2786 s/iter. Eval: 0.0008 s/iter. Total: 0.2819 s/iter. ETA=0:03:25\n",
      "\u001b[32m[04/01 18:43:23 d2.evaluation.evaluator]: \u001b[0mInference done 2002/2712. Dataloading: 0.0023 s/iter. Inference: 0.2784 s/iter. Eval: 0.0008 s/iter. Total: 0.2817 s/iter. ETA=0:03:20\n",
      "\u001b[32m[04/01 18:43:28 d2.evaluation.evaluator]: \u001b[0mInference done 2021/2712. Dataloading: 0.0023 s/iter. Inference: 0.2782 s/iter. Eval: 0.0008 s/iter. Total: 0.2815 s/iter. ETA=0:03:14\n",
      "\u001b[32m[04/01 18:43:34 d2.evaluation.evaluator]: \u001b[0mInference done 2039/2712. Dataloading: 0.0023 s/iter. Inference: 0.2783 s/iter. Eval: 0.0009 s/iter. Total: 0.2816 s/iter. ETA=0:03:09\n",
      "\u001b[32m[04/01 18:43:39 d2.evaluation.evaluator]: \u001b[0mInference done 2058/2712. Dataloading: 0.0023 s/iter. Inference: 0.2783 s/iter. Eval: 0.0009 s/iter. Total: 0.2816 s/iter. ETA=0:03:04\n",
      "\u001b[32m[04/01 18:43:44 d2.evaluation.evaluator]: \u001b[0mInference done 2076/2712. Dataloading: 0.0023 s/iter. Inference: 0.2783 s/iter. Eval: 0.0009 s/iter. Total: 0.2816 s/iter. ETA=0:02:59\n",
      "\u001b[32m[04/01 18:43:49 d2.evaluation.evaluator]: \u001b[0mInference done 2095/2712. Dataloading: 0.0023 s/iter. Inference: 0.2783 s/iter. Eval: 0.0009 s/iter. Total: 0.2816 s/iter. ETA=0:02:53\n",
      "\u001b[32m[04/01 18:43:55 d2.evaluation.evaluator]: \u001b[0mInference done 2113/2712. Dataloading: 0.0023 s/iter. Inference: 0.2784 s/iter. Eval: 0.0009 s/iter. Total: 0.2816 s/iter. ETA=0:02:48\n",
      "\u001b[32m[04/01 18:44:00 d2.evaluation.evaluator]: \u001b[0mInference done 2132/2712. Dataloading: 0.0023 s/iter. Inference: 0.2783 s/iter. Eval: 0.0009 s/iter. Total: 0.2816 s/iter. ETA=0:02:43\n",
      "\u001b[32m[04/01 18:44:05 d2.evaluation.evaluator]: \u001b[0mInference done 2150/2712. Dataloading: 0.0022 s/iter. Inference: 0.2784 s/iter. Eval: 0.0009 s/iter. Total: 0.2817 s/iter. ETA=0:02:38\n",
      "\u001b[32m[04/01 18:44:10 d2.evaluation.evaluator]: \u001b[0mInference done 2170/2712. Dataloading: 0.0022 s/iter. Inference: 0.2782 s/iter. Eval: 0.0009 s/iter. Total: 0.2815 s/iter. ETA=0:02:32\n",
      "\u001b[32m[04/01 18:44:15 d2.evaluation.evaluator]: \u001b[0mInference done 2189/2712. Dataloading: 0.0022 s/iter. Inference: 0.2781 s/iter. Eval: 0.0009 s/iter. Total: 0.2814 s/iter. ETA=0:02:27\n",
      "\u001b[32m[04/01 18:44:20 d2.evaluation.evaluator]: \u001b[0mInference done 2208/2712. Dataloading: 0.0023 s/iter. Inference: 0.2779 s/iter. Eval: 0.0009 s/iter. Total: 0.2812 s/iter. ETA=0:02:21\n",
      "\u001b[32m[04/01 18:44:25 d2.evaluation.evaluator]: \u001b[0mInference done 2227/2712. Dataloading: 0.0023 s/iter. Inference: 0.2777 s/iter. Eval: 0.0009 s/iter. Total: 0.2811 s/iter. ETA=0:02:16\n",
      "\u001b[32m[04/01 18:44:31 d2.evaluation.evaluator]: \u001b[0mInference done 2246/2712. Dataloading: 0.0023 s/iter. Inference: 0.2776 s/iter. Eval: 0.0009 s/iter. Total: 0.2810 s/iter. ETA=0:02:10\n",
      "\u001b[32m[04/01 18:44:36 d2.evaluation.evaluator]: \u001b[0mInference done 2264/2712. Dataloading: 0.0023 s/iter. Inference: 0.2777 s/iter. Eval: 0.0009 s/iter. Total: 0.2811 s/iter. ETA=0:02:05\n",
      "\u001b[32m[04/01 18:44:41 d2.evaluation.evaluator]: \u001b[0mInference done 2283/2712. Dataloading: 0.0023 s/iter. Inference: 0.2776 s/iter. Eval: 0.0009 s/iter. Total: 0.2809 s/iter. ETA=0:02:00\n",
      "\u001b[32m[04/01 18:44:46 d2.evaluation.evaluator]: \u001b[0mInference done 2301/2712. Dataloading: 0.0023 s/iter. Inference: 0.2777 s/iter. Eval: 0.0008 s/iter. Total: 0.2811 s/iter. ETA=0:01:55\n",
      "\u001b[32m[04/01 18:44:51 d2.evaluation.evaluator]: \u001b[0mInference done 2320/2712. Dataloading: 0.0023 s/iter. Inference: 0.2777 s/iter. Eval: 0.0008 s/iter. Total: 0.2810 s/iter. ETA=0:01:50\n",
      "\u001b[32m[04/01 18:44:57 d2.evaluation.evaluator]: \u001b[0mInference done 2337/2712. Dataloading: 0.0023 s/iter. Inference: 0.2778 s/iter. Eval: 0.0008 s/iter. Total: 0.2812 s/iter. ETA=0:01:45\n",
      "\u001b[32m[04/01 18:45:02 d2.evaluation.evaluator]: \u001b[0mInference done 2355/2712. Dataloading: 0.0023 s/iter. Inference: 0.2780 s/iter. Eval: 0.0008 s/iter. Total: 0.2813 s/iter. ETA=0:01:40\n",
      "\u001b[32m[04/01 18:45:07 d2.evaluation.evaluator]: \u001b[0mInference done 2374/2712. Dataloading: 0.0024 s/iter. Inference: 0.2778 s/iter. Eval: 0.0008 s/iter. Total: 0.2812 s/iter. ETA=0:01:35\n",
      "\u001b[32m[04/01 18:45:12 d2.evaluation.evaluator]: \u001b[0mInference done 2393/2712. Dataloading: 0.0024 s/iter. Inference: 0.2778 s/iter. Eval: 0.0008 s/iter. Total: 0.2812 s/iter. ETA=0:01:29\n",
      "\u001b[32m[04/01 18:45:17 d2.evaluation.evaluator]: \u001b[0mInference done 2411/2712. Dataloading: 0.0024 s/iter. Inference: 0.2778 s/iter. Eval: 0.0008 s/iter. Total: 0.2812 s/iter. ETA=0:01:24\n",
      "\u001b[32m[04/01 18:45:22 d2.evaluation.evaluator]: \u001b[0mInference done 2430/2712. Dataloading: 0.0024 s/iter. Inference: 0.2777 s/iter. Eval: 0.0008 s/iter. Total: 0.2811 s/iter. ETA=0:01:19\n",
      "\u001b[32m[04/01 18:45:28 d2.evaluation.evaluator]: \u001b[0mInference done 2447/2712. Dataloading: 0.0024 s/iter. Inference: 0.2779 s/iter. Eval: 0.0008 s/iter. Total: 0.2812 s/iter. ETA=0:01:14\n",
      "\u001b[32m[04/01 18:45:33 d2.evaluation.evaluator]: \u001b[0mInference done 2466/2712. Dataloading: 0.0024 s/iter. Inference: 0.2778 s/iter. Eval: 0.0008 s/iter. Total: 0.2811 s/iter. ETA=0:01:09\n",
      "\u001b[32m[04/01 18:45:38 d2.evaluation.evaluator]: \u001b[0mInference done 2485/2712. Dataloading: 0.0024 s/iter. Inference: 0.2778 s/iter. Eval: 0.0008 s/iter. Total: 0.2812 s/iter. ETA=0:01:03\n",
      "\u001b[32m[04/01 18:45:43 d2.evaluation.evaluator]: \u001b[0mInference done 2504/2712. Dataloading: 0.0024 s/iter. Inference: 0.2778 s/iter. Eval: 0.0008 s/iter. Total: 0.2811 s/iter. ETA=0:00:58\n",
      "\u001b[32m[04/01 18:45:49 d2.evaluation.evaluator]: \u001b[0mInference done 2524/2712. Dataloading: 0.0024 s/iter. Inference: 0.2776 s/iter. Eval: 0.0008 s/iter. Total: 0.2810 s/iter. ETA=0:00:52\n",
      "\u001b[32m[04/01 18:45:54 d2.evaluation.evaluator]: \u001b[0mInference done 2543/2712. Dataloading: 0.0024 s/iter. Inference: 0.2775 s/iter. Eval: 0.0008 s/iter. Total: 0.2809 s/iter. ETA=0:00:47\n",
      "\u001b[32m[04/01 18:45:59 d2.evaluation.evaluator]: \u001b[0mInference done 2561/2712. Dataloading: 0.0024 s/iter. Inference: 0.2775 s/iter. Eval: 0.0008 s/iter. Total: 0.2809 s/iter. ETA=0:00:42\n",
      "\u001b[32m[04/01 18:46:04 d2.evaluation.evaluator]: \u001b[0mInference done 2579/2712. Dataloading: 0.0024 s/iter. Inference: 0.2776 s/iter. Eval: 0.0008 s/iter. Total: 0.2809 s/iter. ETA=0:00:37\n",
      "\u001b[32m[04/01 18:46:09 d2.evaluation.evaluator]: \u001b[0mInference done 2598/2712. Dataloading: 0.0024 s/iter. Inference: 0.2775 s/iter. Eval: 0.0008 s/iter. Total: 0.2808 s/iter. ETA=0:00:32\n",
      "\u001b[32m[04/01 18:46:14 d2.evaluation.evaluator]: \u001b[0mInference done 2617/2712. Dataloading: 0.0024 s/iter. Inference: 0.2774 s/iter. Eval: 0.0008 s/iter. Total: 0.2807 s/iter. ETA=0:00:26\n",
      "\u001b[32m[04/01 18:46:19 d2.evaluation.evaluator]: \u001b[0mInference done 2635/2712. Dataloading: 0.0024 s/iter. Inference: 0.2774 s/iter. Eval: 0.0008 s/iter. Total: 0.2808 s/iter. ETA=0:00:21\n",
      "\u001b[32m[04/01 18:46:24 d2.evaluation.evaluator]: \u001b[0mInference done 2652/2712. Dataloading: 0.0024 s/iter. Inference: 0.2775 s/iter. Eval: 0.0008 s/iter. Total: 0.2809 s/iter. ETA=0:00:16\n",
      "\u001b[32m[04/01 18:46:30 d2.evaluation.evaluator]: \u001b[0mInference done 2671/2712. Dataloading: 0.0024 s/iter. Inference: 0.2775 s/iter. Eval: 0.0008 s/iter. Total: 0.2808 s/iter. ETA=0:00:11\n",
      "\u001b[32m[04/01 18:46:35 d2.evaluation.evaluator]: \u001b[0mInference done 2690/2712. Dataloading: 0.0024 s/iter. Inference: 0.2774 s/iter. Eval: 0.0008 s/iter. Total: 0.2807 s/iter. ETA=0:00:06\n",
      "\u001b[32m[04/01 18:46:40 d2.evaluation.evaluator]: \u001b[0mInference done 2708/2712. Dataloading: 0.0024 s/iter. Inference: 0.2774 s/iter. Eval: 0.0008 s/iter. Total: 0.2807 s/iter. ETA=0:00:01\n",
      "\u001b[32m[04/01 18:46:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:12:40.020163 (0.280761 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/01 18:46:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:12:30 (0.277382 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/01 18:46:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/01 18:46:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output/coco_instances_results.json\n",
      "\u001b[32m[04/01 18:46:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.70s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[04/01 18:46:44 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[04/01 18:46:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 1.56 seconds.\n",
      "\u001b[32m[04/01 18:46:45 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[04/01 18:46:46 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.42 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.038\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.110\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.009\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.016\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.102\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.065\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.104\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.072\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.114\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.213\n",
      "\u001b[32m[04/01 18:46:46 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 3.789 | 11.028 | 0.929  | 1.552 | 4.477 | 10.198 |\n",
      "\u001b[32m[04/01 18:46:46 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP    | category   | AP    | category   | AP     |\n",
      "|:-----------|:------|:-----------|:------|:-----------|:-------|\n",
      "| Bus        | 0.000 | Bike       | 7.132 | Car        | 11.493 |\n",
      "| Pedestrian | 0.314 | Truck      | 0.009 |            |        |\n",
      "\u001b[32m[04/01 18:46:46 d2.engine.defaults]: \u001b[0mEvaluation results for fisheye8k_val in csv format:\n",
      "\u001b[32m[04/01 18:46:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[04/01 18:46:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[04/01 18:46:46 d2.evaluation.testing]: \u001b[0mcopypaste: 3.7895,11.0281,0.9291,1.5516,4.4773,10.1985\n",
      "\u001b[32m[04/01 18:46:46 d2.utils.events]: \u001b[0m eta: 0:03:31  iter: 199  total_loss: 1.478  loss_cls: 0.5799  loss_box_reg: 0.6266  loss_rpn_cls: 0.06396  loss_rpn_loc: 0.2149    time: 1.9913  last_time: 2.6318  data_time: 0.6142  last_data_time: 0.9638   lr: 0.00016592  max_mem: 45332M\n",
      "\u001b[32m[04/01 18:47:26 d2.utils.events]: \u001b[0m eta: 0:02:49  iter: 219  total_loss: 1.458  loss_cls: 0.57  loss_box_reg: 0.6259  loss_rpn_cls: 0.06348  loss_rpn_loc: 0.2072    time: 1.9914  last_time: 1.6895  data_time: 0.5924  last_data_time: 0.3830   lr: 0.00018257  max_mem: 45332M\n",
      "\u001b[32m[04/01 18:48:05 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 239  total_loss: 1.516  loss_cls: 0.5802  loss_box_reg: 0.6488  loss_rpn_cls: 0.06315  loss_rpn_loc: 0.2098    time: 1.9894  last_time: 1.1827  data_time: 0.5896  last_data_time: 0.1592   lr: 0.00019922  max_mem: 45332M\n",
      "\u001b[32m[04/01 18:48:45 d2.utils.events]: \u001b[0m eta: 0:01:24  iter: 259  total_loss: 1.47  loss_cls: 0.5531  loss_box_reg: 0.6405  loss_rpn_cls: 0.05741  loss_rpn_loc: 0.1915    time: 1.9879  last_time: 2.2128  data_time: 0.6009  last_data_time: 0.7191   lr: 0.00021587  max_mem: 45332M\n",
      "\u001b[32m[04/01 18:49:25 d2.utils.events]: \u001b[0m eta: 0:00:42  iter: 279  total_loss: 1.455  loss_cls: 0.5392  loss_box_reg: 0.6503  loss_rpn_cls: 0.05203  loss_rpn_loc: 0.2044    time: 1.9892  last_time: 2.5953  data_time: 0.6012  last_data_time: 0.9522   lr: 0.00023252  max_mem: 45332M\n",
      "\u001b[32m[04/01 18:50:05 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 299  total_loss: 1.457  loss_cls: 0.5365  loss_box_reg: 0.6372  loss_rpn_cls: 0.05454  loss_rpn_loc: 0.2039    time: 1.9887  last_time: 2.3795  data_time: 0.5759  last_data_time: 0.9049   lr: 0.00024917  max_mem: 45332M\n",
      "\u001b[32m[04/01 18:50:05 d2.engine.hooks]: \u001b[0mOverall training speed: 298 iterations in 0:09:52 (1.9887 s / it)\n",
      "\u001b[32m[04/01 18:50:05 d2.engine.hooks]: \u001b[0mTotal training time: 0:36:05 (0:26:12 on hooks)\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/01 18:50:06 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/01 18:50:06 d2.data.datasets.coco]: \u001b[0mLoaded 2712 images in COCO format from /workspace/FishEye8k/dataset/Fisheye8K_all_including_train/test/test.json\n",
      "\u001b[32m[04/01 18:50:06 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[04/01 18:50:06 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[04/01 18:50:06 d2.data.common]: \u001b[0mSerializing 2712 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/01 18:50:06 d2.data.common]: \u001b[0mSerialized dataset takes 2.01 MiB\n",
      "\u001b[32m[04/01 18:50:06 d2.evaluation.evaluator]: \u001b[0mStart inference on 2712 batches\n",
      "\u001b[32m[04/01 18:50:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/2712. Dataloading: 0.0005 s/iter. Inference: 0.3159 s/iter. Eval: 0.0002 s/iter. Total: 0.3167 s/iter. ETA=0:14:15\n",
      "\u001b[32m[04/01 18:50:20 d2.evaluation.evaluator]: \u001b[0mInference done 27/2712. Dataloading: 0.0009 s/iter. Inference: 0.3168 s/iter. Eval: 0.0005 s/iter. Total: 0.3183 s/iter. ETA=0:14:14\n",
      "\u001b[32m[04/01 18:50:25 d2.evaluation.evaluator]: \u001b[0mInference done 45/2712. Dataloading: 0.0009 s/iter. Inference: 0.3034 s/iter. Eval: 0.0004 s/iter. Total: 0.3048 s/iter. ETA=0:13:32\n",
      "\u001b[32m[04/01 18:50:31 d2.evaluation.evaluator]: \u001b[0mInference done 64/2712. Dataloading: 0.0010 s/iter. Inference: 0.2918 s/iter. Eval: 0.0004 s/iter. Total: 0.2933 s/iter. ETA=0:12:56\n",
      "\u001b[32m[04/01 18:50:36 d2.evaluation.evaluator]: \u001b[0mInference done 83/2712. Dataloading: 0.0010 s/iter. Inference: 0.2857 s/iter. Eval: 0.0004 s/iter. Total: 0.2872 s/iter. ETA=0:12:35\n",
      "\u001b[32m[04/01 18:50:41 d2.evaluation.evaluator]: \u001b[0mInference done 101/2712. Dataloading: 0.0010 s/iter. Inference: 0.2840 s/iter. Eval: 0.0004 s/iter. Total: 0.2855 s/iter. ETA=0:12:25\n",
      "\u001b[32m[04/01 18:50:46 d2.evaluation.evaluator]: \u001b[0mInference done 119/2712. Dataloading: 0.0010 s/iter. Inference: 0.2835 s/iter. Eval: 0.0004 s/iter. Total: 0.2850 s/iter. ETA=0:12:19\n",
      "\u001b[32m[04/01 18:50:51 d2.evaluation.evaluator]: \u001b[0mInference done 138/2712. Dataloading: 0.0010 s/iter. Inference: 0.2819 s/iter. Eval: 0.0004 s/iter. Total: 0.2834 s/iter. ETA=0:12:09\n",
      "\u001b[32m[04/01 18:50:56 d2.evaluation.evaluator]: \u001b[0mInference done 157/2712. Dataloading: 0.0011 s/iter. Inference: 0.2820 s/iter. Eval: 0.0004 s/iter. Total: 0.2836 s/iter. ETA=0:12:04\n",
      "\u001b[32m[04/01 18:51:01 d2.evaluation.evaluator]: \u001b[0mInference done 173/2712. Dataloading: 0.0015 s/iter. Inference: 0.2849 s/iter. Eval: 0.0004 s/iter. Total: 0.2869 s/iter. ETA=0:12:08\n",
      "\u001b[32m[04/01 18:51:07 d2.evaluation.evaluator]: \u001b[0mInference done 191/2712. Dataloading: 0.0015 s/iter. Inference: 0.2846 s/iter. Eval: 0.0004 s/iter. Total: 0.2866 s/iter. ETA=0:12:02\n",
      "\u001b[32m[04/01 18:51:12 d2.evaluation.evaluator]: \u001b[0mInference done 209/2712. Dataloading: 0.0014 s/iter. Inference: 0.2849 s/iter. Eval: 0.0004 s/iter. Total: 0.2868 s/iter. ETA=0:11:57\n",
      "\u001b[32m[04/01 18:51:17 d2.evaluation.evaluator]: \u001b[0mInference done 227/2712. Dataloading: 0.0014 s/iter. Inference: 0.2847 s/iter. Eval: 0.0004 s/iter. Total: 0.2865 s/iter. ETA=0:11:51\n",
      "\u001b[32m[04/01 18:51:22 d2.evaluation.evaluator]: \u001b[0mInference done 246/2712. Dataloading: 0.0014 s/iter. Inference: 0.2837 s/iter. Eval: 0.0004 s/iter. Total: 0.2855 s/iter. ETA=0:11:44\n",
      "\u001b[32m[04/01 18:51:27 d2.evaluation.evaluator]: \u001b[0mInference done 264/2712. Dataloading: 0.0014 s/iter. Inference: 0.2835 s/iter. Eval: 0.0004 s/iter. Total: 0.2854 s/iter. ETA=0:11:38\n",
      "\u001b[32m[04/01 18:51:32 d2.evaluation.evaluator]: \u001b[0mInference done 283/2712. Dataloading: 0.0013 s/iter. Inference: 0.2831 s/iter. Eval: 0.0004 s/iter. Total: 0.2849 s/iter. ETA=0:11:32\n",
      "\u001b[32m[04/01 18:51:37 d2.evaluation.evaluator]: \u001b[0mInference done 302/2712. Dataloading: 0.0013 s/iter. Inference: 0.2817 s/iter. Eval: 0.0004 s/iter. Total: 0.2835 s/iter. ETA=0:11:23\n",
      "\u001b[32m[04/01 18:51:43 d2.evaluation.evaluator]: \u001b[0mInference done 322/2712. Dataloading: 0.0013 s/iter. Inference: 0.2806 s/iter. Eval: 0.0004 s/iter. Total: 0.2823 s/iter. ETA=0:11:14\n",
      "\u001b[32m[04/01 18:51:48 d2.evaluation.evaluator]: \u001b[0mInference done 341/2712. Dataloading: 0.0013 s/iter. Inference: 0.2798 s/iter. Eval: 0.0004 s/iter. Total: 0.2816 s/iter. ETA=0:11:07\n",
      "\u001b[32m[04/01 18:51:53 d2.evaluation.evaluator]: \u001b[0mInference done 361/2712. Dataloading: 0.0015 s/iter. Inference: 0.2790 s/iter. Eval: 0.0004 s/iter. Total: 0.2809 s/iter. ETA=0:11:00\n",
      "\u001b[32m[04/01 18:51:59 d2.evaluation.evaluator]: \u001b[0mInference done 381/2712. Dataloading: 0.0015 s/iter. Inference: 0.2781 s/iter. Eval: 0.0004 s/iter. Total: 0.2801 s/iter. ETA=0:10:52\n",
      "\u001b[32m[04/01 18:52:04 d2.evaluation.evaluator]: \u001b[0mInference done 400/2712. Dataloading: 0.0014 s/iter. Inference: 0.2773 s/iter. Eval: 0.0004 s/iter. Total: 0.2792 s/iter. ETA=0:10:45\n",
      "\u001b[32m[04/01 18:52:09 d2.evaluation.evaluator]: \u001b[0mInference done 419/2712. Dataloading: 0.0014 s/iter. Inference: 0.2769 s/iter. Eval: 0.0004 s/iter. Total: 0.2787 s/iter. ETA=0:10:39\n",
      "\u001b[32m[04/01 18:52:14 d2.evaluation.evaluator]: \u001b[0mInference done 437/2712. Dataloading: 0.0014 s/iter. Inference: 0.2768 s/iter. Eval: 0.0004 s/iter. Total: 0.2787 s/iter. ETA=0:10:34\n",
      "\u001b[32m[04/01 18:52:19 d2.evaluation.evaluator]: \u001b[0mInference done 454/2712. Dataloading: 0.0017 s/iter. Inference: 0.2775 s/iter. Eval: 0.0004 s/iter. Total: 0.2797 s/iter. ETA=0:10:31\n",
      "\u001b[32m[04/01 18:52:24 d2.evaluation.evaluator]: \u001b[0mInference done 473/2712. Dataloading: 0.0017 s/iter. Inference: 0.2773 s/iter. Eval: 0.0004 s/iter. Total: 0.2795 s/iter. ETA=0:10:25\n",
      "\u001b[32m[04/01 18:52:29 d2.evaluation.evaluator]: \u001b[0mInference done 493/2712. Dataloading: 0.0017 s/iter. Inference: 0.2765 s/iter. Eval: 0.0004 s/iter. Total: 0.2787 s/iter. ETA=0:10:18\n",
      "\u001b[32m[04/01 18:52:34 d2.evaluation.evaluator]: \u001b[0mInference done 511/2712. Dataloading: 0.0017 s/iter. Inference: 0.2769 s/iter. Eval: 0.0004 s/iter. Total: 0.2790 s/iter. ETA=0:10:14\n",
      "\u001b[32m[04/01 18:52:39 d2.evaluation.evaluator]: \u001b[0mInference done 529/2712. Dataloading: 0.0016 s/iter. Inference: 0.2765 s/iter. Eval: 0.0008 s/iter. Total: 0.2790 s/iter. ETA=0:10:09\n",
      "\u001b[32m[04/01 18:52:45 d2.evaluation.evaluator]: \u001b[0mInference done 546/2712. Dataloading: 0.0016 s/iter. Inference: 0.2772 s/iter. Eval: 0.0008 s/iter. Total: 0.2797 s/iter. ETA=0:10:05\n",
      "\u001b[32m[04/01 18:52:50 d2.evaluation.evaluator]: \u001b[0mInference done 562/2712. Dataloading: 0.0019 s/iter. Inference: 0.2782 s/iter. Eval: 0.0008 s/iter. Total: 0.2810 s/iter. ETA=0:10:04\n",
      "\u001b[32m[04/01 18:52:55 d2.evaluation.evaluator]: \u001b[0mInference done 578/2712. Dataloading: 0.0019 s/iter. Inference: 0.2793 s/iter. Eval: 0.0007 s/iter. Total: 0.2820 s/iter. ETA=0:10:01\n",
      "\u001b[32m[04/01 18:53:00 d2.evaluation.evaluator]: \u001b[0mInference done 594/2712. Dataloading: 0.0018 s/iter. Inference: 0.2802 s/iter. Eval: 0.0007 s/iter. Total: 0.2829 s/iter. ETA=0:09:59\n",
      "\u001b[32m[04/01 18:53:05 d2.evaluation.evaluator]: \u001b[0mInference done 612/2712. Dataloading: 0.0018 s/iter. Inference: 0.2804 s/iter. Eval: 0.0007 s/iter. Total: 0.2830 s/iter. ETA=0:09:54\n",
      "\u001b[32m[04/01 18:53:10 d2.evaluation.evaluator]: \u001b[0mInference done 632/2712. Dataloading: 0.0018 s/iter. Inference: 0.2799 s/iter. Eval: 0.0007 s/iter. Total: 0.2825 s/iter. ETA=0:09:47\n",
      "\u001b[32m[04/01 18:53:16 d2.evaluation.evaluator]: \u001b[0mInference done 650/2712. Dataloading: 0.0018 s/iter. Inference: 0.2802 s/iter. Eval: 0.0007 s/iter. Total: 0.2828 s/iter. ETA=0:09:43\n",
      "\u001b[32m[04/01 18:53:21 d2.evaluation.evaluator]: \u001b[0mInference done 667/2712. Dataloading: 0.0018 s/iter. Inference: 0.2805 s/iter. Eval: 0.0007 s/iter. Total: 0.2831 s/iter. ETA=0:09:38\n",
      "\u001b[32m[04/01 18:53:26 d2.evaluation.evaluator]: \u001b[0mInference done 685/2712. Dataloading: 0.0017 s/iter. Inference: 0.2807 s/iter. Eval: 0.0007 s/iter. Total: 0.2832 s/iter. ETA=0:09:34\n",
      "\u001b[32m[04/01 18:53:31 d2.evaluation.evaluator]: \u001b[0mInference done 705/2712. Dataloading: 0.0017 s/iter. Inference: 0.2799 s/iter. Eval: 0.0007 s/iter. Total: 0.2824 s/iter. ETA=0:09:26\n",
      "\u001b[32m[04/01 18:53:36 d2.evaluation.evaluator]: \u001b[0mInference done 724/2712. Dataloading: 0.0018 s/iter. Inference: 0.2795 s/iter. Eval: 0.0007 s/iter. Total: 0.2821 s/iter. ETA=0:09:20\n",
      "\u001b[32m[04/01 18:53:41 d2.evaluation.evaluator]: \u001b[0mInference done 742/2712. Dataloading: 0.0018 s/iter. Inference: 0.2794 s/iter. Eval: 0.0007 s/iter. Total: 0.2820 s/iter. ETA=0:09:15\n",
      "\u001b[32m[04/01 18:53:46 d2.evaluation.evaluator]: \u001b[0mInference done 761/2712. Dataloading: 0.0018 s/iter. Inference: 0.2792 s/iter. Eval: 0.0007 s/iter. Total: 0.2817 s/iter. ETA=0:09:09\n",
      "\u001b[32m[04/01 18:53:51 d2.evaluation.evaluator]: \u001b[0mInference done 779/2712. Dataloading: 0.0018 s/iter. Inference: 0.2793 s/iter. Eval: 0.0006 s/iter. Total: 0.2818 s/iter. ETA=0:09:04\n",
      "\u001b[32m[04/01 18:53:56 d2.evaluation.evaluator]: \u001b[0mInference done 797/2712. Dataloading: 0.0018 s/iter. Inference: 0.2792 s/iter. Eval: 0.0006 s/iter. Total: 0.2818 s/iter. ETA=0:08:59\n",
      "\u001b[32m[04/01 18:54:01 d2.evaluation.evaluator]: \u001b[0mInference done 815/2712. Dataloading: 0.0018 s/iter. Inference: 0.2792 s/iter. Eval: 0.0006 s/iter. Total: 0.2817 s/iter. ETA=0:08:54\n",
      "\u001b[32m[04/01 18:54:07 d2.evaluation.evaluator]: \u001b[0mInference done 835/2712. Dataloading: 0.0018 s/iter. Inference: 0.2788 s/iter. Eval: 0.0006 s/iter. Total: 0.2813 s/iter. ETA=0:08:48\n",
      "\u001b[32m[04/01 18:54:12 d2.evaluation.evaluator]: \u001b[0mInference done 854/2712. Dataloading: 0.0018 s/iter. Inference: 0.2785 s/iter. Eval: 0.0006 s/iter. Total: 0.2810 s/iter. ETA=0:08:42\n",
      "\u001b[32m[04/01 18:54:17 d2.evaluation.evaluator]: \u001b[0mInference done 869/2712. Dataloading: 0.0018 s/iter. Inference: 0.2796 s/iter. Eval: 0.0006 s/iter. Total: 0.2821 s/iter. ETA=0:08:39\n",
      "\u001b[32m[04/01 18:54:22 d2.evaluation.evaluator]: \u001b[0mInference done 887/2712. Dataloading: 0.0020 s/iter. Inference: 0.2795 s/iter. Eval: 0.0006 s/iter. Total: 0.2822 s/iter. ETA=0:08:35\n",
      "\u001b[32m[04/01 18:54:27 d2.evaluation.evaluator]: \u001b[0mInference done 906/2712. Dataloading: 0.0019 s/iter. Inference: 0.2795 s/iter. Eval: 0.0006 s/iter. Total: 0.2821 s/iter. ETA=0:08:29\n",
      "\u001b[32m[04/01 18:54:33 d2.evaluation.evaluator]: \u001b[0mInference done 925/2712. Dataloading: 0.0020 s/iter. Inference: 0.2793 s/iter. Eval: 0.0006 s/iter. Total: 0.2820 s/iter. ETA=0:08:23\n",
      "\u001b[32m[04/01 18:54:38 d2.evaluation.evaluator]: \u001b[0mInference done 944/2712. Dataloading: 0.0020 s/iter. Inference: 0.2790 s/iter. Eval: 0.0006 s/iter. Total: 0.2817 s/iter. ETA=0:08:18\n",
      "\u001b[32m[04/01 18:54:43 d2.evaluation.evaluator]: \u001b[0mInference done 963/2712. Dataloading: 0.0020 s/iter. Inference: 0.2790 s/iter. Eval: 0.0006 s/iter. Total: 0.2816 s/iter. ETA=0:08:12\n",
      "\u001b[32m[04/01 18:54:48 d2.evaluation.evaluator]: \u001b[0mInference done 983/2712. Dataloading: 0.0019 s/iter. Inference: 0.2784 s/iter. Eval: 0.0006 s/iter. Total: 0.2810 s/iter. ETA=0:08:05\n",
      "\u001b[32m[04/01 18:54:53 d2.evaluation.evaluator]: \u001b[0mInference done 1000/2712. Dataloading: 0.0019 s/iter. Inference: 0.2786 s/iter. Eval: 0.0006 s/iter. Total: 0.2812 s/iter. ETA=0:08:01\n",
      "\u001b[32m[04/01 18:54:58 d2.evaluation.evaluator]: \u001b[0mInference done 1020/2712. Dataloading: 0.0020 s/iter. Inference: 0.2781 s/iter. Eval: 0.0006 s/iter. Total: 0.2808 s/iter. ETA=0:07:55\n",
      "\u001b[32m[04/01 18:55:03 d2.evaluation.evaluator]: \u001b[0mInference done 1040/2712. Dataloading: 0.0020 s/iter. Inference: 0.2778 s/iter. Eval: 0.0006 s/iter. Total: 0.2804 s/iter. ETA=0:07:48\n",
      "\u001b[32m[04/01 18:55:09 d2.evaluation.evaluator]: \u001b[0mInference done 1060/2712. Dataloading: 0.0020 s/iter. Inference: 0.2773 s/iter. Eval: 0.0006 s/iter. Total: 0.2800 s/iter. ETA=0:07:42\n",
      "\u001b[32m[04/01 18:55:14 d2.evaluation.evaluator]: \u001b[0mInference done 1078/2712. Dataloading: 0.0020 s/iter. Inference: 0.2773 s/iter. Eval: 0.0006 s/iter. Total: 0.2800 s/iter. ETA=0:07:37\n",
      "\u001b[32m[04/01 18:55:19 d2.evaluation.evaluator]: \u001b[0mInference done 1097/2712. Dataloading: 0.0020 s/iter. Inference: 0.2772 s/iter. Eval: 0.0006 s/iter. Total: 0.2799 s/iter. ETA=0:07:31\n",
      "\u001b[32m[04/01 18:55:24 d2.evaluation.evaluator]: \u001b[0mInference done 1116/2712. Dataloading: 0.0021 s/iter. Inference: 0.2769 s/iter. Eval: 0.0006 s/iter. Total: 0.2797 s/iter. ETA=0:07:26\n",
      "\u001b[32m[04/01 18:55:29 d2.evaluation.evaluator]: \u001b[0mInference done 1136/2712. Dataloading: 0.0021 s/iter. Inference: 0.2766 s/iter. Eval: 0.0006 s/iter. Total: 0.2793 s/iter. ETA=0:07:20\n",
      "\u001b[32m[04/01 18:55:34 d2.evaluation.evaluator]: \u001b[0mInference done 1154/2712. Dataloading: 0.0021 s/iter. Inference: 0.2767 s/iter. Eval: 0.0006 s/iter. Total: 0.2795 s/iter. ETA=0:07:15\n",
      "\u001b[32m[04/01 18:55:39 d2.evaluation.evaluator]: \u001b[0mInference done 1173/2712. Dataloading: 0.0020 s/iter. Inference: 0.2766 s/iter. Eval: 0.0005 s/iter. Total: 0.2793 s/iter. ETA=0:07:09\n",
      "\u001b[32m[04/01 18:55:45 d2.evaluation.evaluator]: \u001b[0mInference done 1188/2712. Dataloading: 0.0020 s/iter. Inference: 0.2775 s/iter. Eval: 0.0005 s/iter. Total: 0.2801 s/iter. ETA=0:07:06\n",
      "\u001b[32m[04/01 18:55:50 d2.evaluation.evaluator]: \u001b[0mInference done 1207/2712. Dataloading: 0.0020 s/iter. Inference: 0.2775 s/iter. Eval: 0.0005 s/iter. Total: 0.2801 s/iter. ETA=0:07:01\n",
      "\u001b[32m[04/01 18:55:55 d2.evaluation.evaluator]: \u001b[0mInference done 1225/2712. Dataloading: 0.0020 s/iter. Inference: 0.2777 s/iter. Eval: 0.0005 s/iter. Total: 0.2803 s/iter. ETA=0:06:56\n",
      "\u001b[32m[04/01 18:56:00 d2.evaluation.evaluator]: \u001b[0mInference done 1245/2712. Dataloading: 0.0020 s/iter. Inference: 0.2773 s/iter. Eval: 0.0005 s/iter. Total: 0.2800 s/iter. ETA=0:06:50\n",
      "\u001b[32m[04/01 18:56:06 d2.evaluation.evaluator]: \u001b[0mInference done 1261/2712. Dataloading: 0.0020 s/iter. Inference: 0.2778 s/iter. Eval: 0.0005 s/iter. Total: 0.2805 s/iter. ETA=0:06:46\n",
      "\u001b[32m[04/01 18:56:11 d2.evaluation.evaluator]: \u001b[0mInference done 1280/2712. Dataloading: 0.0020 s/iter. Inference: 0.2776 s/iter. Eval: 0.0005 s/iter. Total: 0.2802 s/iter. ETA=0:06:41\n",
      "\u001b[32m[04/01 18:56:16 d2.evaluation.evaluator]: \u001b[0mInference done 1299/2712. Dataloading: 0.0020 s/iter. Inference: 0.2773 s/iter. Eval: 0.0007 s/iter. Total: 0.2801 s/iter. ETA=0:06:35\n",
      "\u001b[32m[04/01 18:56:21 d2.evaluation.evaluator]: \u001b[0mInference done 1318/2712. Dataloading: 0.0020 s/iter. Inference: 0.2774 s/iter. Eval: 0.0007 s/iter. Total: 0.2801 s/iter. ETA=0:06:30\n",
      "\u001b[32m[04/01 18:56:26 d2.evaluation.evaluator]: \u001b[0mInference done 1334/2712. Dataloading: 0.0020 s/iter. Inference: 0.2778 s/iter. Eval: 0.0007 s/iter. Total: 0.2806 s/iter. ETA=0:06:26\n",
      "\u001b[32m[04/01 18:56:31 d2.evaluation.evaluator]: \u001b[0mInference done 1353/2712. Dataloading: 0.0020 s/iter. Inference: 0.2778 s/iter. Eval: 0.0007 s/iter. Total: 0.2805 s/iter. ETA=0:06:21\n",
      "\u001b[32m[04/01 18:56:36 d2.evaluation.evaluator]: \u001b[0mInference done 1372/2712. Dataloading: 0.0019 s/iter. Inference: 0.2776 s/iter. Eval: 0.0007 s/iter. Total: 0.2803 s/iter. ETA=0:06:15\n",
      "\u001b[32m[04/01 18:56:42 d2.evaluation.evaluator]: \u001b[0mInference done 1391/2712. Dataloading: 0.0019 s/iter. Inference: 0.2775 s/iter. Eval: 0.0007 s/iter. Total: 0.2802 s/iter. ETA=0:06:10\n",
      "\u001b[32m[04/01 18:56:47 d2.evaluation.evaluator]: \u001b[0mInference done 1409/2712. Dataloading: 0.0019 s/iter. Inference: 0.2777 s/iter. Eval: 0.0007 s/iter. Total: 0.2803 s/iter. ETA=0:06:05\n",
      "\u001b[32m[04/01 18:56:52 d2.evaluation.evaluator]: \u001b[0mInference done 1427/2712. Dataloading: 0.0019 s/iter. Inference: 0.2777 s/iter. Eval: 0.0007 s/iter. Total: 0.2804 s/iter. ETA=0:06:00\n",
      "\u001b[32m[04/01 18:56:57 d2.evaluation.evaluator]: \u001b[0mInference done 1445/2712. Dataloading: 0.0019 s/iter. Inference: 0.2777 s/iter. Eval: 0.0006 s/iter. Total: 0.2804 s/iter. ETA=0:05:55\n",
      "\u001b[32m[04/01 18:57:02 d2.evaluation.evaluator]: \u001b[0mInference done 1465/2712. Dataloading: 0.0019 s/iter. Inference: 0.2774 s/iter. Eval: 0.0006 s/iter. Total: 0.2801 s/iter. ETA=0:05:49\n",
      "\u001b[32m[04/01 18:57:07 d2.evaluation.evaluator]: \u001b[0mInference done 1483/2712. Dataloading: 0.0019 s/iter. Inference: 0.2774 s/iter. Eval: 0.0006 s/iter. Total: 0.2801 s/iter. ETA=0:05:44\n",
      "\u001b[32m[04/01 18:57:12 d2.evaluation.evaluator]: \u001b[0mInference done 1502/2712. Dataloading: 0.0019 s/iter. Inference: 0.2772 s/iter. Eval: 0.0006 s/iter. Total: 0.2799 s/iter. ETA=0:05:38\n",
      "\u001b[32m[04/01 18:57:17 d2.evaluation.evaluator]: \u001b[0mInference done 1521/2712. Dataloading: 0.0019 s/iter. Inference: 0.2771 s/iter. Eval: 0.0006 s/iter. Total: 0.2798 s/iter. ETA=0:05:33\n",
      "\u001b[32m[04/01 18:57:23 d2.evaluation.evaluator]: \u001b[0mInference done 1541/2712. Dataloading: 0.0019 s/iter. Inference: 0.2769 s/iter. Eval: 0.0006 s/iter. Total: 0.2796 s/iter. ETA=0:05:27\n",
      "\u001b[32m[04/01 18:57:28 d2.evaluation.evaluator]: \u001b[0mInference done 1560/2712. Dataloading: 0.0019 s/iter. Inference: 0.2768 s/iter. Eval: 0.0006 s/iter. Total: 0.2795 s/iter. ETA=0:05:21\n",
      "\u001b[32m[04/01 18:57:33 d2.evaluation.evaluator]: \u001b[0mInference done 1579/2712. Dataloading: 0.0019 s/iter. Inference: 0.2768 s/iter. Eval: 0.0006 s/iter. Total: 0.2795 s/iter. ETA=0:05:16\n",
      "\u001b[32m[04/01 18:57:38 d2.evaluation.evaluator]: \u001b[0mInference done 1598/2712. Dataloading: 0.0020 s/iter. Inference: 0.2766 s/iter. Eval: 0.0006 s/iter. Total: 0.2793 s/iter. ETA=0:05:11\n",
      "\u001b[32m[04/01 18:57:43 d2.evaluation.evaluator]: \u001b[0mInference done 1617/2712. Dataloading: 0.0020 s/iter. Inference: 0.2765 s/iter. Eval: 0.0006 s/iter. Total: 0.2792 s/iter. ETA=0:05:05\n",
      "\u001b[32m[04/01 18:57:49 d2.evaluation.evaluator]: \u001b[0mInference done 1634/2712. Dataloading: 0.0020 s/iter. Inference: 0.2768 s/iter. Eval: 0.0006 s/iter. Total: 0.2796 s/iter. ETA=0:05:01\n",
      "\u001b[32m[04/01 18:57:54 d2.evaluation.evaluator]: \u001b[0mInference done 1651/2712. Dataloading: 0.0019 s/iter. Inference: 0.2772 s/iter. Eval: 0.0006 s/iter. Total: 0.2799 s/iter. ETA=0:04:56\n",
      "\u001b[32m[04/01 18:57:59 d2.evaluation.evaluator]: \u001b[0mInference done 1670/2712. Dataloading: 0.0019 s/iter. Inference: 0.2770 s/iter. Eval: 0.0006 s/iter. Total: 0.2798 s/iter. ETA=0:04:51\n",
      "\u001b[32m[04/01 18:58:04 d2.evaluation.evaluator]: \u001b[0mInference done 1688/2712. Dataloading: 0.0019 s/iter. Inference: 0.2771 s/iter. Eval: 0.0006 s/iter. Total: 0.2799 s/iter. ETA=0:04:46\n",
      "\u001b[32m[04/01 18:58:09 d2.evaluation.evaluator]: \u001b[0mInference done 1708/2712. Dataloading: 0.0019 s/iter. Inference: 0.2769 s/iter. Eval: 0.0006 s/iter. Total: 0.2796 s/iter. ETA=0:04:40\n",
      "\u001b[32m[04/01 18:58:15 d2.evaluation.evaluator]: \u001b[0mInference done 1727/2712. Dataloading: 0.0019 s/iter. Inference: 0.2769 s/iter. Eval: 0.0006 s/iter. Total: 0.2796 s/iter. ETA=0:04:35\n",
      "\u001b[32m[04/01 18:58:20 d2.evaluation.evaluator]: \u001b[0mInference done 1747/2712. Dataloading: 0.0019 s/iter. Inference: 0.2767 s/iter. Eval: 0.0006 s/iter. Total: 0.2794 s/iter. ETA=0:04:29\n",
      "\u001b[32m[04/01 18:58:25 d2.evaluation.evaluator]: \u001b[0mInference done 1766/2712. Dataloading: 0.0020 s/iter. Inference: 0.2765 s/iter. Eval: 0.0006 s/iter. Total: 0.2793 s/iter. ETA=0:04:24\n",
      "\u001b[32m[04/01 18:58:30 d2.evaluation.evaluator]: \u001b[0mInference done 1784/2712. Dataloading: 0.0020 s/iter. Inference: 0.2766 s/iter. Eval: 0.0006 s/iter. Total: 0.2794 s/iter. ETA=0:04:19\n",
      "\u001b[32m[04/01 18:58:35 d2.evaluation.evaluator]: \u001b[0mInference done 1801/2712. Dataloading: 0.0020 s/iter. Inference: 0.2769 s/iter. Eval: 0.0006 s/iter. Total: 0.2796 s/iter. ETA=0:04:14\n",
      "\u001b[32m[04/01 18:58:40 d2.evaluation.evaluator]: \u001b[0mInference done 1820/2712. Dataloading: 0.0020 s/iter. Inference: 0.2767 s/iter. Eval: 0.0006 s/iter. Total: 0.2795 s/iter. ETA=0:04:09\n",
      "\u001b[32m[04/01 18:58:46 d2.evaluation.evaluator]: \u001b[0mInference done 1838/2712. Dataloading: 0.0020 s/iter. Inference: 0.2767 s/iter. Eval: 0.0006 s/iter. Total: 0.2795 s/iter. ETA=0:04:04\n",
      "\u001b[32m[04/01 18:58:51 d2.evaluation.evaluator]: \u001b[0mInference done 1857/2712. Dataloading: 0.0020 s/iter. Inference: 0.2766 s/iter. Eval: 0.0006 s/iter. Total: 0.2794 s/iter. ETA=0:03:58\n",
      "\u001b[32m[04/01 18:58:56 d2.evaluation.evaluator]: \u001b[0mInference done 1875/2712. Dataloading: 0.0020 s/iter. Inference: 0.2768 s/iter. Eval: 0.0006 s/iter. Total: 0.2795 s/iter. ETA=0:03:53\n",
      "\u001b[32m[04/01 18:59:01 d2.evaluation.evaluator]: \u001b[0mInference done 1895/2712. Dataloading: 0.0020 s/iter. Inference: 0.2766 s/iter. Eval: 0.0006 s/iter. Total: 0.2793 s/iter. ETA=0:03:48\n",
      "\u001b[32m[04/01 18:59:06 d2.evaluation.evaluator]: \u001b[0mInference done 1914/2712. Dataloading: 0.0019 s/iter. Inference: 0.2766 s/iter. Eval: 0.0006 s/iter. Total: 0.2793 s/iter. ETA=0:03:42\n",
      "\u001b[32m[04/01 18:59:12 d2.evaluation.evaluator]: \u001b[0mInference done 1933/2712. Dataloading: 0.0019 s/iter. Inference: 0.2766 s/iter. Eval: 0.0006 s/iter. Total: 0.2793 s/iter. ETA=0:03:37\n",
      "\u001b[32m[04/01 18:59:17 d2.evaluation.evaluator]: \u001b[0mInference done 1951/2712. Dataloading: 0.0019 s/iter. Inference: 0.2767 s/iter. Eval: 0.0006 s/iter. Total: 0.2793 s/iter. ETA=0:03:32\n",
      "\u001b[32m[04/01 18:59:22 d2.evaluation.evaluator]: \u001b[0mInference done 1971/2712. Dataloading: 0.0019 s/iter. Inference: 0.2764 s/iter. Eval: 0.0006 s/iter. Total: 0.2791 s/iter. ETA=0:03:26\n",
      "\u001b[32m[04/01 18:59:27 d2.evaluation.evaluator]: \u001b[0mInference done 1990/2712. Dataloading: 0.0019 s/iter. Inference: 0.2763 s/iter. Eval: 0.0006 s/iter. Total: 0.2790 s/iter. ETA=0:03:21\n",
      "\u001b[32m[04/01 18:59:32 d2.evaluation.evaluator]: \u001b[0mInference done 2010/2712. Dataloading: 0.0019 s/iter. Inference: 0.2762 s/iter. Eval: 0.0006 s/iter. Total: 0.2789 s/iter. ETA=0:03:15\n",
      "\u001b[32m[04/01 18:59:37 d2.evaluation.evaluator]: \u001b[0mInference done 2027/2712. Dataloading: 0.0019 s/iter. Inference: 0.2764 s/iter. Eval: 0.0006 s/iter. Total: 0.2790 s/iter. ETA=0:03:11\n",
      "\u001b[32m[04/01 18:59:43 d2.evaluation.evaluator]: \u001b[0mInference done 2046/2712. Dataloading: 0.0019 s/iter. Inference: 0.2763 s/iter. Eval: 0.0006 s/iter. Total: 0.2790 s/iter. ETA=0:03:05\n",
      "\u001b[32m[04/01 18:59:48 d2.evaluation.evaluator]: \u001b[0mInference done 2065/2712. Dataloading: 0.0019 s/iter. Inference: 0.2762 s/iter. Eval: 0.0006 s/iter. Total: 0.2789 s/iter. ETA=0:03:00\n",
      "\u001b[32m[04/01 18:59:53 d2.evaluation.evaluator]: \u001b[0mInference done 2085/2712. Dataloading: 0.0019 s/iter. Inference: 0.2761 s/iter. Eval: 0.0006 s/iter. Total: 0.2787 s/iter. ETA=0:02:54\n",
      "\u001b[32m[04/01 18:59:58 d2.evaluation.evaluator]: \u001b[0mInference done 2104/2712. Dataloading: 0.0019 s/iter. Inference: 0.2760 s/iter. Eval: 0.0006 s/iter. Total: 0.2786 s/iter. ETA=0:02:49\n"
     ]
    }
   ],
   "source": [
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return DatasetEvaluators([COCOEvaluator(\"fisheye8k_val\", output_dir=\"./output\")])\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"fisheye8k_train\",)\n",
    "cfg.DATASETS.TEST = (\"fisheye8k_val\",)\n",
    "cfg.TEST.EVAL_PERIOD = 100\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 32  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025   # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []          # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b43a2d-60bd-4a52-bfcd-84d3d650771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f3447b-b2e7-43e8-9d89-128894a1a5ab",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca0ba19-4a16-450d-8733-36f18f6b3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d045dd14-b864-43ba-9f7c-3bc17336559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "fisheye_metadata = MetadataCatalog.get(\"fisheye8k_train\")\n",
    "\n",
    "with open(\"/workspace/FishEye8k/dataset/Fisheye8K_all_including_train/train/train.json\") as f:\n",
    "    imgs_anns = json.load(f)\n",
    "imgs_anns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf462a-fa14-4c74-9256-62ec673b9c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dicts = imgs_anns[\"images\"]\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    f = d[\"file_name\"]\n",
    "    im = cv2.imread(f\"/workspace/FishEye8k/dataset/Fisheye8K_all_including_train/train/images/{f}\")\n",
    "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=fisheye_metadata, \n",
    "                   scale=0.5)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    plt.figure(figsize=(16,9))\n",
    "    plt.imshow(out.get_image()[:, :, ::-1])\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e456b2a2-2745-4ef3-99fe-a4b0aad40e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"fisheye8k_val\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"fisheye8k_val\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
    "# another equivalent way to evaluate the model is to use `trainer.test`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
