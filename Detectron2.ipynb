{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf2c87b0-bfe1-4ea8-a3db-b1e3cd88470b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Jun__8_16:49:14_PDT_2022\n",
      "Cuda compilation tools, release 11.7, V11.7.99\n",
      "Build cuda_11.7.r11.7/compiler.31442593_0\n",
      "torch:  1.11 ; cuda:  cu113\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "787e1aac-16ab-45f7-8973-a27cb696c96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# from google.colab.patches import cv2_imshow\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2.evaluation import COCOEvaluator, DatasetEvaluators\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3292c3b5-3cfe-4caa-908d-04fb78706468",
   "metadata": {},
   "source": [
    "# Fisheye Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81fa366f-37ad-4cb2-864f-a977ac447694",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Dataset 'fisheye8k_train' is already registered!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdetectron2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m register_coco_instances\n\u001b[0;32m----> 2\u001b[0m \u001b[43mregister_coco_instances\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfisheye8k_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/workspace/FishEye8k/dataset/Fisheye8K_all_including_train/train/train.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/workspace/FishEye8k/dataset/Fisheye8K_all_including_train/train/images\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m register_coco_instances(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfisheye8k_val\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}, \n\u001b[1;32m      6\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/workspace/FishEye8k/dataset/Fisheye8K_all_including_train/test/test.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      7\u001b[0m                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/workspace/FishEye8k/dataset/Fisheye8K_all_including_train/test/images\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/data/datasets/coco.py:541\u001b[0m, in \u001b[0;36mregister_coco_instances\u001b[0;34m(name, metadata, json_file, image_root)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image_root, (\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)), image_root\n\u001b[1;32m    540\u001b[0m \u001b[38;5;66;03m# 1. register a function which returns dicts\u001b[39;00m\n\u001b[0;32m--> 541\u001b[0m \u001b[43mDatasetCatalog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregister\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_coco_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;66;03m# 2. Optionally, add metadata about this dataset,\u001b[39;00m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;66;03m# since they might be useful in evaluation, visualization or logging\u001b[39;00m\n\u001b[1;32m    545\u001b[0m MetadataCatalog\u001b[38;5;241m.\u001b[39mget(name)\u001b[38;5;241m.\u001b[39mset(\n\u001b[1;32m    546\u001b[0m     json_file\u001b[38;5;241m=\u001b[39mjson_file, image_root\u001b[38;5;241m=\u001b[39mimage_root, evaluator_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoco\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetadata\n\u001b[1;32m    547\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/detectron2/data/catalog.py:37\u001b[0m, in \u001b[0;36m_DatasetCatalog.register\u001b[0;34m(self, name, func)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m    name (str): the name that identifies a dataset, e.g. \"coco_2014_train\".\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03m    func (callable): a callable which takes no arguments and returns a list of dicts.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m        It must return the same results if called multiple times.\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must register a function with `DatasetCatalog.register`!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is already registered!\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m[name] \u001b[38;5;241m=\u001b[39m func\n",
      "\u001b[0;31mAssertionError\u001b[0m: Dataset 'fisheye8k_train' is already registered!"
     ]
    }
   ],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"fisheye8k_train\", {}, \n",
    "                        \"/workspace/FishEye8k/dataset/Fisheye8K_all_including_train/train/train.json\", \n",
    "                        \"/workspace/FishEye8k/dataset/Fisheye8K_all_including_train/train/images\")\n",
    "register_coco_instances(\"fisheye8k_val\", {}, \n",
    "                        \"/workspace/FishEye8k/dataset/Fisheye8K_all_including_train/test/test.json\", \n",
    "                        \"/workspace/FishEye8k/dataset/Fisheye8K_all_including_train/test/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c86372-073f-4057-978c-9142072878f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/01 18:13:48 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=6, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=20, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/01 18:13:49 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/01 18:13:49 d2.data.datasets.coco]: \u001b[0mLoaded 5288 images in COCO format from /workspace/FishEye8k/dataset/Fisheye8K_all_including_train/train/train.json\n",
      "\u001b[32m[04/01 18:13:49 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 5288 images left.\n",
      "\u001b[32m[04/01 18:13:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[04/01 18:13:49 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[04/01 18:13:49 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[04/01 18:13:49 d2.data.common]: \u001b[0mSerializing 5288 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/01 18:13:49 d2.data.common]: \u001b[0mSerialized dataset takes 4.66 MiB\n",
      "\u001b[32m[04/01 18:13:49 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=32\n",
      "\u001b[32m[04/01 18:13:49 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (6, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (6,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (20, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (20,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/01 18:13:49 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[04/01 18:14:35 d2.utils.events]: \u001b[0m eta: 0:09:09  iter: 19  total_loss: 3.698  loss_cls: 1.943  loss_box_reg: 0.3966  loss_rpn_cls: 1.021  loss_rpn_loc: 0.2996    time: 1.9180  last_time: 1.7007  data_time: 0.9120  last_data_time: 0.5298   lr: 1.6068e-05  max_mem: 45332M\n",
      "\u001b[32m[04/01 18:15:15 d2.utils.events]: \u001b[0m eta: 0:09:04  iter: 39  total_loss: 2.474  loss_cls: 1.617  loss_box_reg: 0.4158  loss_rpn_cls: 0.1503  loss_rpn_loc: 0.2575    time: 1.9783  last_time: 2.3698  data_time: 0.6254  last_data_time: 0.7745   lr: 3.2718e-05  max_mem: 45332M\n",
      "\u001b[32m[04/01 18:15:56 d2.utils.events]: \u001b[0m eta: 0:08:39  iter: 59  total_loss: 1.905  loss_cls: 1.011  loss_box_reg: 0.4574  loss_rpn_cls: 0.1081  loss_rpn_loc: 0.2573    time: 1.9921  last_time: 2.3148  data_time: 0.6562  last_data_time: 0.7267   lr: 4.9367e-05  max_mem: 45332M\n",
      "\u001b[32m[04/01 18:16:36 d2.utils.events]: \u001b[0m eta: 0:07:56  iter: 79  total_loss: 1.479  loss_cls: 0.6611  loss_box_reg: 0.4838  loss_rpn_cls: 0.09542  loss_rpn_loc: 0.2442    time: 2.0024  last_time: 2.0241  data_time: 0.6399  last_data_time: 0.5828   lr: 6.6017e-05  max_mem: 45332M\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/01 18:17:17 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/01 18:17:17 d2.data.datasets.coco]: \u001b[0mLoaded 2712 images in COCO format from /workspace/FishEye8k/dataset/Fisheye8K_all_including_train/test/test.json\n",
      "\u001b[32m[04/01 18:17:17 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[04/01 18:17:17 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[04/01 18:17:17 d2.data.common]: \u001b[0mSerializing 2712 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/01 18:17:17 d2.data.common]: \u001b[0mSerialized dataset takes 2.01 MiB\n",
      "\u001b[32m[04/01 18:17:17 d2.evaluation.evaluator]: \u001b[0mStart inference on 2712 batches\n",
      "\u001b[32m[04/01 18:17:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/2712. Dataloading: 0.0008 s/iter. Inference: 0.3029 s/iter. Eval: 0.0002 s/iter. Total: 0.3039 s/iter. ETA=0:13:40\n",
      "\u001b[32m[04/01 18:17:32 d2.evaluation.evaluator]: \u001b[0mInference done 29/2712. Dataloading: 0.0010 s/iter. Inference: 0.2912 s/iter. Eval: 0.0002 s/iter. Total: 0.2925 s/iter. ETA=0:13:04\n",
      "\u001b[32m[04/01 18:17:37 d2.evaluation.evaluator]: \u001b[0mInference done 47/2712. Dataloading: 0.0011 s/iter. Inference: 0.2870 s/iter. Eval: 0.0003 s/iter. Total: 0.2885 s/iter. ETA=0:12:48\n",
      "\u001b[32m[04/01 18:17:42 d2.evaluation.evaluator]: \u001b[0mInference done 64/2712. Dataloading: 0.0011 s/iter. Inference: 0.2921 s/iter. Eval: 0.0003 s/iter. Total: 0.2936 s/iter. ETA=0:12:57\n",
      "\u001b[32m[04/01 18:17:47 d2.evaluation.evaluator]: \u001b[0mInference done 81/2712. Dataloading: 0.0012 s/iter. Inference: 0.2934 s/iter. Eval: 0.0003 s/iter. Total: 0.2950 s/iter. ETA=0:12:56\n",
      "\u001b[32m[04/01 18:17:52 d2.evaluation.evaluator]: \u001b[0mInference done 99/2712. Dataloading: 0.0021 s/iter. Inference: 0.2903 s/iter. Eval: 0.0003 s/iter. Total: 0.2928 s/iter. ETA=0:12:44\n",
      "\u001b[32m[04/01 18:17:57 d2.evaluation.evaluator]: \u001b[0mInference done 117/2712. Dataloading: 0.0027 s/iter. Inference: 0.2891 s/iter. Eval: 0.0003 s/iter. Total: 0.2921 s/iter. ETA=0:12:38\n",
      "\u001b[32m[04/01 18:18:02 d2.evaluation.evaluator]: \u001b[0mInference done 135/2712. Dataloading: 0.0031 s/iter. Inference: 0.2875 s/iter. Eval: 0.0003 s/iter. Total: 0.2909 s/iter. ETA=0:12:29\n",
      "\u001b[32m[04/01 18:18:08 d2.evaluation.evaluator]: \u001b[0mInference done 153/2712. Dataloading: 0.0028 s/iter. Inference: 0.2875 s/iter. Eval: 0.0003 s/iter. Total: 0.2907 s/iter. ETA=0:12:23\n",
      "\u001b[32m[04/01 18:18:13 d2.evaluation.evaluator]: \u001b[0mInference done 170/2712. Dataloading: 0.0026 s/iter. Inference: 0.2886 s/iter. Eval: 0.0003 s/iter. Total: 0.2916 s/iter. ETA=0:12:21\n",
      "\u001b[32m[04/01 18:18:18 d2.evaluation.evaluator]: \u001b[0mInference done 188/2712. Dataloading: 0.0029 s/iter. Inference: 0.2886 s/iter. Eval: 0.0003 s/iter. Total: 0.2919 s/iter. ETA=0:12:16\n",
      "\u001b[32m[04/01 18:18:23 d2.evaluation.evaluator]: \u001b[0mInference done 207/2712. Dataloading: 0.0027 s/iter. Inference: 0.2876 s/iter. Eval: 0.0003 s/iter. Total: 0.2907 s/iter. ETA=0:12:08\n",
      "\u001b[32m[04/01 18:18:29 d2.evaluation.evaluator]: \u001b[0mInference done 226/2712. Dataloading: 0.0026 s/iter. Inference: 0.2867 s/iter. Eval: 0.0003 s/iter. Total: 0.2897 s/iter. ETA=0:12:00\n",
      "\u001b[32m[04/01 18:18:34 d2.evaluation.evaluator]: \u001b[0mInference done 244/2712. Dataloading: 0.0028 s/iter. Inference: 0.2864 s/iter. Eval: 0.0003 s/iter. Total: 0.2896 s/iter. ETA=0:11:54\n",
      "\u001b[32m[04/01 18:18:39 d2.evaluation.evaluator]: \u001b[0mInference done 262/2712. Dataloading: 0.0027 s/iter. Inference: 0.2869 s/iter. Eval: 0.0003 s/iter. Total: 0.2900 s/iter. ETA=0:11:50\n",
      "\u001b[32m[04/01 18:18:44 d2.evaluation.evaluator]: \u001b[0mInference done 279/2712. Dataloading: 0.0026 s/iter. Inference: 0.2876 s/iter. Eval: 0.0003 s/iter. Total: 0.2906 s/iter. ETA=0:11:46\n",
      "\u001b[32m[04/01 18:18:49 d2.evaluation.evaluator]: \u001b[0mInference done 298/2712. Dataloading: 0.0025 s/iter. Inference: 0.2866 s/iter. Eval: 0.0003 s/iter. Total: 0.2895 s/iter. ETA=0:11:38\n",
      "\u001b[32m[04/01 18:18:55 d2.evaluation.evaluator]: \u001b[0mInference done 316/2712. Dataloading: 0.0024 s/iter. Inference: 0.2866 s/iter. Eval: 0.0003 s/iter. Total: 0.2894 s/iter. ETA=0:11:33\n",
      "\u001b[32m[04/01 18:19:00 d2.evaluation.evaluator]: \u001b[0mInference done 333/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0003 s/iter. Total: 0.2897 s/iter. ETA=0:11:29\n",
      "\u001b[32m[04/01 18:19:05 d2.evaluation.evaluator]: \u001b[0mInference done 351/2712. Dataloading: 0.0023 s/iter. Inference: 0.2869 s/iter. Eval: 0.0003 s/iter. Total: 0.2896 s/iter. ETA=0:11:23\n",
      "\u001b[32m[04/01 18:19:10 d2.evaluation.evaluator]: \u001b[0mInference done 368/2712. Dataloading: 0.0023 s/iter. Inference: 0.2872 s/iter. Eval: 0.0003 s/iter. Total: 0.2899 s/iter. ETA=0:11:19\n",
      "\u001b[32m[04/01 18:19:15 d2.evaluation.evaluator]: \u001b[0mInference done 385/2712. Dataloading: 0.0022 s/iter. Inference: 0.2875 s/iter. Eval: 0.0003 s/iter. Total: 0.2901 s/iter. ETA=0:11:14\n",
      "\u001b[32m[04/01 18:19:20 d2.evaluation.evaluator]: \u001b[0mInference done 403/2712. Dataloading: 0.0024 s/iter. Inference: 0.2875 s/iter. Eval: 0.0003 s/iter. Total: 0.2903 s/iter. ETA=0:11:10\n",
      "\u001b[32m[04/01 18:19:25 d2.evaluation.evaluator]: \u001b[0mInference done 421/2712. Dataloading: 0.0023 s/iter. Inference: 0.2875 s/iter. Eval: 0.0003 s/iter. Total: 0.2902 s/iter. ETA=0:11:04\n",
      "\u001b[32m[04/01 18:19:31 d2.evaluation.evaluator]: \u001b[0mInference done 438/2712. Dataloading: 0.0023 s/iter. Inference: 0.2882 s/iter. Eval: 0.0003 s/iter. Total: 0.2908 s/iter. ETA=0:11:01\n",
      "\u001b[32m[04/01 18:19:36 d2.evaluation.evaluator]: \u001b[0mInference done 456/2712. Dataloading: 0.0022 s/iter. Inference: 0.2879 s/iter. Eval: 0.0003 s/iter. Total: 0.2905 s/iter. ETA=0:10:55\n",
      "\u001b[32m[04/01 18:19:41 d2.evaluation.evaluator]: \u001b[0mInference done 473/2712. Dataloading: 0.0022 s/iter. Inference: 0.2879 s/iter. Eval: 0.0006 s/iter. Total: 0.2908 s/iter. ETA=0:10:51\n",
      "\u001b[32m[04/01 18:19:46 d2.evaluation.evaluator]: \u001b[0mInference done 491/2712. Dataloading: 0.0022 s/iter. Inference: 0.2879 s/iter. Eval: 0.0006 s/iter. Total: 0.2908 s/iter. ETA=0:10:45\n",
      "\u001b[32m[04/01 18:19:51 d2.evaluation.evaluator]: \u001b[0mInference done 509/2712. Dataloading: 0.0021 s/iter. Inference: 0.2877 s/iter. Eval: 0.0006 s/iter. Total: 0.2905 s/iter. ETA=0:10:40\n",
      "\u001b[32m[04/01 18:19:56 d2.evaluation.evaluator]: \u001b[0mInference done 528/2712. Dataloading: 0.0021 s/iter. Inference: 0.2873 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:10:33\n",
      "\u001b[32m[04/01 18:20:01 d2.evaluation.evaluator]: \u001b[0mInference done 546/2712. Dataloading: 0.0022 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2899 s/iter. ETA=0:10:27\n",
      "\u001b[32m[04/01 18:20:07 d2.evaluation.evaluator]: \u001b[0mInference done 563/2712. Dataloading: 0.0022 s/iter. Inference: 0.2879 s/iter. Eval: 0.0006 s/iter. Total: 0.2907 s/iter. ETA=0:10:24\n",
      "\u001b[32m[04/01 18:20:12 d2.evaluation.evaluator]: \u001b[0mInference done 581/2712. Dataloading: 0.0021 s/iter. Inference: 0.2877 s/iter. Eval: 0.0006 s/iter. Total: 0.2905 s/iter. ETA=0:10:19\n",
      "\u001b[32m[04/01 18:20:17 d2.evaluation.evaluator]: \u001b[0mInference done 599/2712. Dataloading: 0.0021 s/iter. Inference: 0.2878 s/iter. Eval: 0.0006 s/iter. Total: 0.2906 s/iter. ETA=0:10:14\n",
      "\u001b[32m[04/01 18:20:22 d2.evaluation.evaluator]: \u001b[0mInference done 617/2712. Dataloading: 0.0021 s/iter. Inference: 0.2878 s/iter. Eval: 0.0006 s/iter. Total: 0.2906 s/iter. ETA=0:10:08\n",
      "\u001b[32m[04/01 18:20:28 d2.evaluation.evaluator]: \u001b[0mInference done 635/2712. Dataloading: 0.0022 s/iter. Inference: 0.2875 s/iter. Eval: 0.0005 s/iter. Total: 0.2903 s/iter. ETA=0:10:03\n",
      "\u001b[32m[04/01 18:20:33 d2.evaluation.evaluator]: \u001b[0mInference done 653/2712. Dataloading: 0.0023 s/iter. Inference: 0.2872 s/iter. Eval: 0.0005 s/iter. Total: 0.2902 s/iter. ETA=0:09:57\n",
      "\u001b[32m[04/01 18:20:38 d2.evaluation.evaluator]: \u001b[0mInference done 670/2712. Dataloading: 0.0023 s/iter. Inference: 0.2875 s/iter. Eval: 0.0005 s/iter. Total: 0.2904 s/iter. ETA=0:09:52\n",
      "\u001b[32m[04/01 18:20:43 d2.evaluation.evaluator]: \u001b[0mInference done 688/2712. Dataloading: 0.0022 s/iter. Inference: 0.2877 s/iter. Eval: 0.0005 s/iter. Total: 0.2905 s/iter. ETA=0:09:47\n",
      "\u001b[32m[04/01 18:20:48 d2.evaluation.evaluator]: \u001b[0mInference done 707/2712. Dataloading: 0.0022 s/iter. Inference: 0.2874 s/iter. Eval: 0.0005 s/iter. Total: 0.2903 s/iter. ETA=0:09:42\n",
      "\u001b[32m[04/01 18:20:54 d2.evaluation.evaluator]: \u001b[0mInference done 725/2712. Dataloading: 0.0022 s/iter. Inference: 0.2873 s/iter. Eval: 0.0005 s/iter. Total: 0.2902 s/iter. ETA=0:09:36\n",
      "\u001b[32m[04/01 18:20:59 d2.evaluation.evaluator]: \u001b[0mInference done 743/2712. Dataloading: 0.0022 s/iter. Inference: 0.2873 s/iter. Eval: 0.0005 s/iter. Total: 0.2901 s/iter. ETA=0:09:31\n",
      "\u001b[32m[04/01 18:21:04 d2.evaluation.evaluator]: \u001b[0mInference done 762/2712. Dataloading: 0.0021 s/iter. Inference: 0.2870 s/iter. Eval: 0.0005 s/iter. Total: 0.2899 s/iter. ETA=0:09:25\n",
      "\u001b[32m[04/01 18:21:09 d2.evaluation.evaluator]: \u001b[0mInference done 780/2712. Dataloading: 0.0021 s/iter. Inference: 0.2868 s/iter. Eval: 0.0005 s/iter. Total: 0.2896 s/iter. ETA=0:09:19\n",
      "\u001b[32m[04/01 18:21:14 d2.evaluation.evaluator]: \u001b[0mInference done 798/2712. Dataloading: 0.0021 s/iter. Inference: 0.2869 s/iter. Eval: 0.0005 s/iter. Total: 0.2897 s/iter. ETA=0:09:14\n",
      "\u001b[32m[04/01 18:21:20 d2.evaluation.evaluator]: \u001b[0mInference done 816/2712. Dataloading: 0.0021 s/iter. Inference: 0.2869 s/iter. Eval: 0.0005 s/iter. Total: 0.2896 s/iter. ETA=0:09:09\n",
      "\u001b[32m[04/01 18:21:25 d2.evaluation.evaluator]: \u001b[0mInference done 834/2712. Dataloading: 0.0022 s/iter. Inference: 0.2867 s/iter. Eval: 0.0005 s/iter. Total: 0.2895 s/iter. ETA=0:09:03\n",
      "\u001b[32m[04/01 18:21:30 d2.evaluation.evaluator]: \u001b[0mInference done 852/2712. Dataloading: 0.0021 s/iter. Inference: 0.2867 s/iter. Eval: 0.0005 s/iter. Total: 0.2895 s/iter. ETA=0:08:58\n",
      "\u001b[32m[04/01 18:21:35 d2.evaluation.evaluator]: \u001b[0mInference done 869/2712. Dataloading: 0.0022 s/iter. Inference: 0.2867 s/iter. Eval: 0.0005 s/iter. Total: 0.2896 s/iter. ETA=0:08:53\n",
      "\u001b[32m[04/01 18:21:40 d2.evaluation.evaluator]: \u001b[0mInference done 886/2712. Dataloading: 0.0022 s/iter. Inference: 0.2869 s/iter. Eval: 0.0005 s/iter. Total: 0.2898 s/iter. ETA=0:08:49\n",
      "\u001b[32m[04/01 18:21:45 d2.evaluation.evaluator]: \u001b[0mInference done 903/2712. Dataloading: 0.0022 s/iter. Inference: 0.2871 s/iter. Eval: 0.0005 s/iter. Total: 0.2899 s/iter. ETA=0:08:44\n",
      "\u001b[32m[04/01 18:21:50 d2.evaluation.evaluator]: \u001b[0mInference done 921/2712. Dataloading: 0.0023 s/iter. Inference: 0.2869 s/iter. Eval: 0.0005 s/iter. Total: 0.2898 s/iter. ETA=0:08:38\n",
      "\u001b[32m[04/01 18:21:55 d2.evaluation.evaluator]: \u001b[0mInference done 939/2712. Dataloading: 0.0022 s/iter. Inference: 0.2868 s/iter. Eval: 0.0005 s/iter. Total: 0.2896 s/iter. ETA=0:08:33\n",
      "\u001b[32m[04/01 18:22:00 d2.evaluation.evaluator]: \u001b[0mInference done 957/2712. Dataloading: 0.0022 s/iter. Inference: 0.2868 s/iter. Eval: 0.0005 s/iter. Total: 0.2896 s/iter. ETA=0:08:28\n",
      "\u001b[32m[04/01 18:22:06 d2.evaluation.evaluator]: \u001b[0mInference done 975/2712. Dataloading: 0.0022 s/iter. Inference: 0.2868 s/iter. Eval: 0.0005 s/iter. Total: 0.2896 s/iter. ETA=0:08:23\n",
      "\u001b[32m[04/01 18:22:11 d2.evaluation.evaluator]: \u001b[0mInference done 993/2712. Dataloading: 0.0023 s/iter. Inference: 0.2865 s/iter. Eval: 0.0004 s/iter. Total: 0.2894 s/iter. ETA=0:08:17\n",
      "\u001b[32m[04/01 18:22:16 d2.evaluation.evaluator]: \u001b[0mInference done 1010/2712. Dataloading: 0.0023 s/iter. Inference: 0.2866 s/iter. Eval: 0.0004 s/iter. Total: 0.2896 s/iter. ETA=0:08:12\n",
      "\u001b[32m[04/01 18:22:21 d2.evaluation.evaluator]: \u001b[0mInference done 1029/2712. Dataloading: 0.0024 s/iter. Inference: 0.2863 s/iter. Eval: 0.0004 s/iter. Total: 0.2893 s/iter. ETA=0:08:06\n",
      "\u001b[32m[04/01 18:22:26 d2.evaluation.evaluator]: \u001b[0mInference done 1047/2712. Dataloading: 0.0024 s/iter. Inference: 0.2863 s/iter. Eval: 0.0004 s/iter. Total: 0.2893 s/iter. ETA=0:08:01\n",
      "\u001b[32m[04/01 18:22:31 d2.evaluation.evaluator]: \u001b[0mInference done 1065/2712. Dataloading: 0.0024 s/iter. Inference: 0.2862 s/iter. Eval: 0.0004 s/iter. Total: 0.2893 s/iter. ETA=0:07:56\n",
      "\u001b[32m[04/01 18:22:36 d2.evaluation.evaluator]: \u001b[0mInference done 1083/2712. Dataloading: 0.0024 s/iter. Inference: 0.2861 s/iter. Eval: 0.0004 s/iter. Total: 0.2891 s/iter. ETA=0:07:50\n",
      "\u001b[32m[04/01 18:22:41 d2.evaluation.evaluator]: \u001b[0mInference done 1100/2712. Dataloading: 0.0024 s/iter. Inference: 0.2862 s/iter. Eval: 0.0004 s/iter. Total: 0.2891 s/iter. ETA=0:07:46\n",
      "\u001b[32m[04/01 18:22:47 d2.evaluation.evaluator]: \u001b[0mInference done 1119/2712. Dataloading: 0.0024 s/iter. Inference: 0.2860 s/iter. Eval: 0.0004 s/iter. Total: 0.2891 s/iter. ETA=0:07:40\n",
      "\u001b[32m[04/01 18:22:52 d2.evaluation.evaluator]: \u001b[0mInference done 1136/2712. Dataloading: 0.0024 s/iter. Inference: 0.2863 s/iter. Eval: 0.0004 s/iter. Total: 0.2893 s/iter. ETA=0:07:35\n",
      "\u001b[32m[04/01 18:22:57 d2.evaluation.evaluator]: \u001b[0mInference done 1153/2712. Dataloading: 0.0024 s/iter. Inference: 0.2865 s/iter. Eval: 0.0004 s/iter. Total: 0.2895 s/iter. ETA=0:07:31\n",
      "\u001b[32m[04/01 18:23:02 d2.evaluation.evaluator]: \u001b[0mInference done 1171/2712. Dataloading: 0.0025 s/iter. Inference: 0.2863 s/iter. Eval: 0.0004 s/iter. Total: 0.2894 s/iter. ETA=0:07:25\n",
      "\u001b[32m[04/01 18:23:07 d2.evaluation.evaluator]: \u001b[0mInference done 1189/2712. Dataloading: 0.0024 s/iter. Inference: 0.2863 s/iter. Eval: 0.0004 s/iter. Total: 0.2893 s/iter. ETA=0:07:20\n",
      "\u001b[32m[04/01 18:23:12 d2.evaluation.evaluator]: \u001b[0mInference done 1207/2712. Dataloading: 0.0024 s/iter. Inference: 0.2861 s/iter. Eval: 0.0004 s/iter. Total: 0.2891 s/iter. ETA=0:07:15\n",
      "\u001b[32m[04/01 18:23:17 d2.evaluation.evaluator]: \u001b[0mInference done 1224/2712. Dataloading: 0.0024 s/iter. Inference: 0.2862 s/iter. Eval: 0.0005 s/iter. Total: 0.2893 s/iter. ETA=0:07:10\n",
      "\u001b[32m[04/01 18:23:22 d2.evaluation.evaluator]: \u001b[0mInference done 1240/2712. Dataloading: 0.0024 s/iter. Inference: 0.2865 s/iter. Eval: 0.0005 s/iter. Total: 0.2896 s/iter. ETA=0:07:06\n",
      "\u001b[32m[04/01 18:23:27 d2.evaluation.evaluator]: \u001b[0mInference done 1258/2712. Dataloading: 0.0024 s/iter. Inference: 0.2864 s/iter. Eval: 0.0005 s/iter. Total: 0.2895 s/iter. ETA=0:07:00\n",
      "\u001b[32m[04/01 18:23:32 d2.evaluation.evaluator]: \u001b[0mInference done 1276/2712. Dataloading: 0.0024 s/iter. Inference: 0.2863 s/iter. Eval: 0.0005 s/iter. Total: 0.2894 s/iter. ETA=0:06:55\n",
      "\u001b[32m[04/01 18:23:37 d2.evaluation.evaluator]: \u001b[0mInference done 1293/2712. Dataloading: 0.0024 s/iter. Inference: 0.2864 s/iter. Eval: 0.0005 s/iter. Total: 0.2895 s/iter. ETA=0:06:50\n",
      "\u001b[32m[04/01 18:23:43 d2.evaluation.evaluator]: \u001b[0mInference done 1311/2712. Dataloading: 0.0024 s/iter. Inference: 0.2864 s/iter. Eval: 0.0005 s/iter. Total: 0.2894 s/iter. ETA=0:06:45\n",
      "\u001b[32m[04/01 18:23:48 d2.evaluation.evaluator]: \u001b[0mInference done 1329/2712. Dataloading: 0.0024 s/iter. Inference: 0.2864 s/iter. Eval: 0.0005 s/iter. Total: 0.2894 s/iter. ETA=0:06:40\n",
      "\u001b[32m[04/01 18:23:53 d2.evaluation.evaluator]: \u001b[0mInference done 1347/2712. Dataloading: 0.0024 s/iter. Inference: 0.2864 s/iter. Eval: 0.0005 s/iter. Total: 0.2895 s/iter. ETA=0:06:35\n",
      "\u001b[32m[04/01 18:23:58 d2.evaluation.evaluator]: \u001b[0mInference done 1365/2712. Dataloading: 0.0024 s/iter. Inference: 0.2865 s/iter. Eval: 0.0005 s/iter. Total: 0.2896 s/iter. ETA=0:06:30\n",
      "\u001b[32m[04/01 18:24:04 d2.evaluation.evaluator]: \u001b[0mInference done 1382/2712. Dataloading: 0.0024 s/iter. Inference: 0.2868 s/iter. Eval: 0.0005 s/iter. Total: 0.2898 s/iter. ETA=0:06:25\n",
      "\u001b[32m[04/01 18:24:09 d2.evaluation.evaluator]: \u001b[0mInference done 1399/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0005 s/iter. Total: 0.2900 s/iter. ETA=0:06:20\n",
      "\u001b[32m[04/01 18:24:14 d2.evaluation.evaluator]: \u001b[0mInference done 1417/2712. Dataloading: 0.0024 s/iter. Inference: 0.2868 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:06:15\n",
      "\u001b[32m[04/01 18:24:19 d2.evaluation.evaluator]: \u001b[0mInference done 1436/2712. Dataloading: 0.0024 s/iter. Inference: 0.2866 s/iter. Eval: 0.0006 s/iter. Total: 0.2897 s/iter. ETA=0:06:09\n",
      "\u001b[32m[04/01 18:24:24 d2.evaluation.evaluator]: \u001b[0mInference done 1453/2712. Dataloading: 0.0024 s/iter. Inference: 0.2867 s/iter. Eval: 0.0005 s/iter. Total: 0.2898 s/iter. ETA=0:06:04\n",
      "\u001b[32m[04/01 18:24:29 d2.evaluation.evaluator]: \u001b[0mInference done 1471/2712. Dataloading: 0.0024 s/iter. Inference: 0.2866 s/iter. Eval: 0.0005 s/iter. Total: 0.2897 s/iter. ETA=0:05:59\n",
      "\u001b[32m[04/01 18:24:34 d2.evaluation.evaluator]: \u001b[0mInference done 1488/2712. Dataloading: 0.0024 s/iter. Inference: 0.2867 s/iter. Eval: 0.0005 s/iter. Total: 0.2898 s/iter. ETA=0:05:54\n",
      "\u001b[32m[04/01 18:24:40 d2.evaluation.evaluator]: \u001b[0mInference done 1505/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0005 s/iter. Total: 0.2899 s/iter. ETA=0:05:49\n",
      "\u001b[32m[04/01 18:24:45 d2.evaluation.evaluator]: \u001b[0mInference done 1523/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0005 s/iter. Total: 0.2899 s/iter. ETA=0:05:44\n",
      "\u001b[32m[04/01 18:24:50 d2.evaluation.evaluator]: \u001b[0mInference done 1540/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0005 s/iter. Total: 0.2900 s/iter. ETA=0:05:39\n",
      "\u001b[32m[04/01 18:24:55 d2.evaluation.evaluator]: \u001b[0mInference done 1558/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0005 s/iter. Total: 0.2900 s/iter. ETA=0:05:34\n",
      "\u001b[32m[04/01 18:25:00 d2.evaluation.evaluator]: \u001b[0mInference done 1576/2712. Dataloading: 0.0024 s/iter. Inference: 0.2868 s/iter. Eval: 0.0005 s/iter. Total: 0.2900 s/iter. ETA=0:05:29\n",
      "\u001b[32m[04/01 18:25:05 d2.evaluation.evaluator]: \u001b[0mInference done 1594/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0005 s/iter. Total: 0.2900 s/iter. ETA=0:05:24\n",
      "\u001b[32m[04/01 18:25:11 d2.evaluation.evaluator]: \u001b[0mInference done 1612/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0005 s/iter. Total: 0.2899 s/iter. ETA=0:05:18\n",
      "\u001b[32m[04/01 18:25:16 d2.evaluation.evaluator]: \u001b[0mInference done 1629/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:05:14\n",
      "\u001b[32m[04/01 18:25:21 d2.evaluation.evaluator]: \u001b[0mInference done 1647/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:05:08\n",
      "\u001b[32m[04/01 18:25:26 d2.evaluation.evaluator]: \u001b[0mInference done 1664/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:05:03\n",
      "\u001b[32m[04/01 18:25:31 d2.evaluation.evaluator]: \u001b[0mInference done 1680/2712. Dataloading: 0.0025 s/iter. Inference: 0.2871 s/iter. Eval: 0.0006 s/iter. Total: 0.2903 s/iter. ETA=0:04:59\n",
      "\u001b[32m[04/01 18:25:36 d2.evaluation.evaluator]: \u001b[0mInference done 1698/2712. Dataloading: 0.0025 s/iter. Inference: 0.2871 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:04:54\n",
      "\u001b[32m[04/01 18:25:41 d2.evaluation.evaluator]: \u001b[0mInference done 1716/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:04:49\n",
      "\u001b[32m[04/01 18:25:46 d2.evaluation.evaluator]: \u001b[0mInference done 1734/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:04:43\n",
      "\u001b[32m[04/01 18:25:51 d2.evaluation.evaluator]: \u001b[0mInference done 1752/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:04:38\n",
      "\u001b[32m[04/01 18:25:57 d2.evaluation.evaluator]: \u001b[0mInference done 1770/2712. Dataloading: 0.0024 s/iter. Inference: 0.2871 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:04:33\n",
      "\u001b[32m[04/01 18:26:02 d2.evaluation.evaluator]: \u001b[0mInference done 1788/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:04:28\n",
      "\u001b[32m[04/01 18:26:07 d2.evaluation.evaluator]: \u001b[0mInference done 1806/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:04:22\n",
      "\u001b[32m[04/01 18:26:12 d2.evaluation.evaluator]: \u001b[0mInference done 1824/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:04:17\n",
      "\u001b[32m[04/01 18:26:18 d2.evaluation.evaluator]: \u001b[0mInference done 1841/2712. Dataloading: 0.0024 s/iter. Inference: 0.2872 s/iter. Eval: 0.0006 s/iter. Total: 0.2903 s/iter. ETA=0:04:12\n",
      "\u001b[32m[04/01 18:26:23 d2.evaluation.evaluator]: \u001b[0mInference done 1859/2712. Dataloading: 0.0023 s/iter. Inference: 0.2872 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:04:07\n",
      "\u001b[32m[04/01 18:26:28 d2.evaluation.evaluator]: \u001b[0mInference done 1877/2712. Dataloading: 0.0023 s/iter. Inference: 0.2871 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:04:02\n",
      "\u001b[32m[04/01 18:26:33 d2.evaluation.evaluator]: \u001b[0mInference done 1895/2712. Dataloading: 0.0024 s/iter. Inference: 0.2871 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:03:57\n",
      "\u001b[32m[04/01 18:26:38 d2.evaluation.evaluator]: \u001b[0mInference done 1913/2712. Dataloading: 0.0024 s/iter. Inference: 0.2872 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:03:51\n",
      "\u001b[32m[04/01 18:26:44 d2.evaluation.evaluator]: \u001b[0mInference done 1932/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:03:46\n",
      "\u001b[32m[04/01 18:26:49 d2.evaluation.evaluator]: \u001b[0mInference done 1950/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:03:41\n",
      "\u001b[32m[04/01 18:26:54 d2.evaluation.evaluator]: \u001b[0mInference done 1968/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:03:35\n",
      "\u001b[32m[04/01 18:26:59 d2.evaluation.evaluator]: \u001b[0mInference done 1986/2712. Dataloading: 0.0023 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:03:30\n",
      "\u001b[32m[04/01 18:27:04 d2.evaluation.evaluator]: \u001b[0mInference done 2004/2712. Dataloading: 0.0023 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:03:25\n",
      "\u001b[32m[04/01 18:27:09 d2.evaluation.evaluator]: \u001b[0mInference done 2021/2712. Dataloading: 0.0023 s/iter. Inference: 0.2871 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:03:20\n",
      "\u001b[32m[04/01 18:27:15 d2.evaluation.evaluator]: \u001b[0mInference done 2039/2712. Dataloading: 0.0023 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:03:15\n",
      "\u001b[32m[04/01 18:27:20 d2.evaluation.evaluator]: \u001b[0mInference done 2057/2712. Dataloading: 0.0023 s/iter. Inference: 0.2870 s/iter. Eval: 0.0005 s/iter. Total: 0.2900 s/iter. ETA=0:03:09\n",
      "\u001b[32m[04/01 18:27:25 d2.evaluation.evaluator]: \u001b[0mInference done 2075/2712. Dataloading: 0.0023 s/iter. Inference: 0.2870 s/iter. Eval: 0.0005 s/iter. Total: 0.2900 s/iter. ETA=0:03:04\n",
      "\u001b[32m[04/01 18:27:30 d2.evaluation.evaluator]: \u001b[0mInference done 2093/2712. Dataloading: 0.0023 s/iter. Inference: 0.2870 s/iter. Eval: 0.0005 s/iter. Total: 0.2900 s/iter. ETA=0:02:59\n",
      "\u001b[32m[04/01 18:27:35 d2.evaluation.evaluator]: \u001b[0mInference done 2111/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0005 s/iter. Total: 0.2900 s/iter. ETA=0:02:54\n",
      "\u001b[32m[04/01 18:27:41 d2.evaluation.evaluator]: \u001b[0mInference done 2129/2712. Dataloading: 0.0023 s/iter. Inference: 0.2870 s/iter. Eval: 0.0005 s/iter. Total: 0.2900 s/iter. ETA=0:02:49\n",
      "\u001b[32m[04/01 18:27:46 d2.evaluation.evaluator]: \u001b[0mInference done 2146/2712. Dataloading: 0.0023 s/iter. Inference: 0.2871 s/iter. Eval: 0.0005 s/iter. Total: 0.2901 s/iter. ETA=0:02:44\n",
      "\u001b[32m[04/01 18:27:51 d2.evaluation.evaluator]: \u001b[0mInference done 2163/2712. Dataloading: 0.0023 s/iter. Inference: 0.2872 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:02:39\n",
      "\u001b[32m[04/01 18:27:56 d2.evaluation.evaluator]: \u001b[0mInference done 2178/2712. Dataloading: 0.0023 s/iter. Inference: 0.2875 s/iter. Eval: 0.0006 s/iter. Total: 0.2905 s/iter. ETA=0:02:35\n",
      "\u001b[32m[04/01 18:28:01 d2.evaluation.evaluator]: \u001b[0mInference done 2195/2712. Dataloading: 0.0023 s/iter. Inference: 0.2875 s/iter. Eval: 0.0006 s/iter. Total: 0.2906 s/iter. ETA=0:02:30\n",
      "\u001b[32m[04/01 18:28:06 d2.evaluation.evaluator]: \u001b[0mInference done 2214/2712. Dataloading: 0.0023 s/iter. Inference: 0.2875 s/iter. Eval: 0.0006 s/iter. Total: 0.2905 s/iter. ETA=0:02:24\n",
      "\u001b[32m[04/01 18:28:11 d2.evaluation.evaluator]: \u001b[0mInference done 2231/2712. Dataloading: 0.0023 s/iter. Inference: 0.2875 s/iter. Eval: 0.0006 s/iter. Total: 0.2905 s/iter. ETA=0:02:19\n",
      "\u001b[32m[04/01 18:28:17 d2.evaluation.evaluator]: \u001b[0mInference done 2249/2712. Dataloading: 0.0023 s/iter. Inference: 0.2875 s/iter. Eval: 0.0006 s/iter. Total: 0.2906 s/iter. ETA=0:02:14\n",
      "\u001b[32m[04/01 18:28:22 d2.evaluation.evaluator]: \u001b[0mInference done 2267/2712. Dataloading: 0.0023 s/iter. Inference: 0.2874 s/iter. Eval: 0.0006 s/iter. Total: 0.2905 s/iter. ETA=0:02:09\n",
      "\u001b[32m[04/01 18:28:27 d2.evaluation.evaluator]: \u001b[0mInference done 2285/2712. Dataloading: 0.0023 s/iter. Inference: 0.2874 s/iter. Eval: 0.0006 s/iter. Total: 0.2905 s/iter. ETA=0:02:04\n",
      "\u001b[32m[04/01 18:28:32 d2.evaluation.evaluator]: \u001b[0mInference done 2302/2712. Dataloading: 0.0024 s/iter. Inference: 0.2875 s/iter. Eval: 0.0006 s/iter. Total: 0.2906 s/iter. ETA=0:01:59\n",
      "\u001b[32m[04/01 18:28:37 d2.evaluation.evaluator]: \u001b[0mInference done 2320/2712. Dataloading: 0.0023 s/iter. Inference: 0.2874 s/iter. Eval: 0.0006 s/iter. Total: 0.2905 s/iter. ETA=0:01:53\n",
      "\u001b[32m[04/01 18:28:42 d2.evaluation.evaluator]: \u001b[0mInference done 2338/2712. Dataloading: 0.0023 s/iter. Inference: 0.2874 s/iter. Eval: 0.0006 s/iter. Total: 0.2904 s/iter. ETA=0:01:48\n",
      "\u001b[32m[04/01 18:28:47 d2.evaluation.evaluator]: \u001b[0mInference done 2355/2712. Dataloading: 0.0023 s/iter. Inference: 0.2875 s/iter. Eval: 0.0006 s/iter. Total: 0.2906 s/iter. ETA=0:01:43\n",
      "\u001b[32m[04/01 18:28:53 d2.evaluation.evaluator]: \u001b[0mInference done 2373/2712. Dataloading: 0.0023 s/iter. Inference: 0.2874 s/iter. Eval: 0.0006 s/iter. Total: 0.2905 s/iter. ETA=0:01:38\n",
      "\u001b[32m[04/01 18:28:58 d2.evaluation.evaluator]: \u001b[0mInference done 2391/2712. Dataloading: 0.0023 s/iter. Inference: 0.2874 s/iter. Eval: 0.0006 s/iter. Total: 0.2905 s/iter. ETA=0:01:33\n",
      "\u001b[32m[04/01 18:29:03 d2.evaluation.evaluator]: \u001b[0mInference done 2409/2712. Dataloading: 0.0023 s/iter. Inference: 0.2874 s/iter. Eval: 0.0006 s/iter. Total: 0.2904 s/iter. ETA=0:01:28\n",
      "\u001b[32m[04/01 18:29:08 d2.evaluation.evaluator]: \u001b[0mInference done 2427/2712. Dataloading: 0.0024 s/iter. Inference: 0.2873 s/iter. Eval: 0.0006 s/iter. Total: 0.2904 s/iter. ETA=0:01:22\n",
      "\u001b[32m[04/01 18:29:13 d2.evaluation.evaluator]: \u001b[0mInference done 2445/2712. Dataloading: 0.0024 s/iter. Inference: 0.2873 s/iter. Eval: 0.0006 s/iter. Total: 0.2904 s/iter. ETA=0:01:17\n",
      "\u001b[32m[04/01 18:29:18 d2.evaluation.evaluator]: \u001b[0mInference done 2463/2712. Dataloading: 0.0023 s/iter. Inference: 0.2872 s/iter. Eval: 0.0006 s/iter. Total: 0.2903 s/iter. ETA=0:01:12\n",
      "\u001b[32m[04/01 18:29:24 d2.evaluation.evaluator]: \u001b[0mInference done 2482/2712. Dataloading: 0.0024 s/iter. Inference: 0.2871 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:01:06\n",
      "\u001b[32m[04/01 18:29:29 d2.evaluation.evaluator]: \u001b[0mInference done 2500/2712. Dataloading: 0.0024 s/iter. Inference: 0.2871 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:01:01\n",
      "\u001b[32m[04/01 18:29:34 d2.evaluation.evaluator]: \u001b[0mInference done 2519/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:00:55\n",
      "\u001b[32m[04/01 18:29:39 d2.evaluation.evaluator]: \u001b[0mInference done 2537/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:00:50\n",
      "\u001b[32m[04/01 18:29:44 d2.evaluation.evaluator]: \u001b[0mInference done 2554/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:00:45\n",
      "\u001b[32m[04/01 18:29:49 d2.evaluation.evaluator]: \u001b[0mInference done 2571/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:00:40\n",
      "\u001b[32m[04/01 18:29:54 d2.evaluation.evaluator]: \u001b[0mInference done 2589/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:00:35\n",
      "\u001b[32m[04/01 18:29:59 d2.evaluation.evaluator]: \u001b[0mInference done 2607/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0006 s/iter. Total: 0.2901 s/iter. ETA=0:00:30\n",
      "\u001b[32m[04/01 18:30:05 d2.evaluation.evaluator]: \u001b[0mInference done 2625/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:00:25\n",
      "\u001b[32m[04/01 18:30:10 d2.evaluation.evaluator]: \u001b[0mInference done 2643/2712. Dataloading: 0.0024 s/iter. Inference: 0.2868 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:00:20\n",
      "\u001b[32m[04/01 18:30:15 d2.evaluation.evaluator]: \u001b[0mInference done 2661/2712. Dataloading: 0.0024 s/iter. Inference: 0.2868 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:00:14\n",
      "\u001b[32m[04/01 18:30:20 d2.evaluation.evaluator]: \u001b[0mInference done 2679/2712. Dataloading: 0.0024 s/iter. Inference: 0.2869 s/iter. Eval: 0.0006 s/iter. Total: 0.2900 s/iter. ETA=0:00:09\n",
      "\u001b[32m[04/01 18:30:26 d2.evaluation.evaluator]: \u001b[0mInference done 2696/2712. Dataloading: 0.0024 s/iter. Inference: 0.2870 s/iter. Eval: 0.0006 s/iter. Total: 0.2902 s/iter. ETA=0:00:04\n",
      "\u001b[32m[04/01 18:30:30 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:13:05.401464 (0.290137 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/01 18:30:30 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:12:56 (0.286890 s / iter per device, on 1 devices)\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return DatasetEvaluators([COCOEvaluator(\"fisheye8k_val\", output_dir=\"./output\")])\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"fisheye8k_train\",)\n",
    "cfg.DATASETS.TEST = (\"fisheye8k_val\",)\n",
    "cfg.TEST.EVAL_PERIOD = 100\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 32  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025   # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n",
    "cfg.SOLVER.STEPS = []          # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # The \"RoIHead batch size\". 128 is faster, and good enough for this toy dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 5  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
    "# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b43a2d-60bd-4a52-bfcd-84d3d650771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f3447b-b2e7-43e8-9d89-128894a1a5ab",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca0ba19-4a16-450d-8733-36f18f6b3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d045dd14-b864-43ba-9f7c-3bc17336559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "fisheye_metadata = MetadataCatalog.get(\"fisheye8k_train\")\n",
    "\n",
    "with open(\"/workspace/FishEye8k/dataset/Fisheye8K_all_including_train/train/train.json\") as f:\n",
    "    imgs_anns = json.load(f)\n",
    "imgs_anns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf462a-fa14-4c74-9256-62ec673b9c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dicts = imgs_anns[\"images\"]\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    f = d[\"file_name\"]\n",
    "    im = cv2.imread(f\"/workspace/FishEye8k/dataset/Fisheye8K_all_including_train/train/images/{f}\")\n",
    "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=fisheye_metadata, \n",
    "                   scale=0.5)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    plt.figure(figsize=(16,9))\n",
    "    plt.imshow(out.get_image()[:, :, ::-1])\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e456b2a2-2745-4ef3-99fe-a4b0aad40e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"fisheye8k_val\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"fisheye8k_val\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
    "# another equivalent way to evaluate the model is to use `trainer.test`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
