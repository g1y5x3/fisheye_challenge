{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fd3af04-e00f-4f48-9d72-d6188dfb2fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, json, wandb, argparse\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from ultralytics.nn.tasks import DetectionModel\n",
    "from utils import get_image_id\n",
    "\n",
    "# libraries that are monkey patched\n",
    "import ultralytics.nn.tasks as tasks\n",
    "import ultralytics.utils.torch_utils as torch_utils\n",
    "from ultralytics.data.augment import Albumentations\n",
    "from ultralytics.models.yolo.detect.train import DetectionTrainer\n",
    "from yolov8_monkey_patches import albumentation_init, load_model_custom, get_flops_pass, parse_dcn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "323496a4-56e7-49f3-973a-e8cbcaee7467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monkey patches\n",
    "Albumentations.__init__ = albumentation_init\n",
    "DetectionTrainer.get_model = load_model_custom\n",
    "tasks.parse_model = parse_dcn_model\n",
    "torch_utils.get_flops = get_flops_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17fbe3e1-ccba-4ef7-a20a-3c04da9d84d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.19 🚀 Python-3.10.13 torch-2.2.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x_dcn.yaml, data=fisheye.yaml, epochs=1, time=None, patience=100, batch=4, imgsz=1280, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=0.1, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=0.5, iou=0.5, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/usr/src/ultralytics/runs/detect/train\n"
     ]
    }
   ],
   "source": [
    "train_args = dict(model=\"yolov8x_dcn.yaml\", data=\"fisheye.yaml\",\n",
    "                  device=0, epochs=1, batch=4, fraction=0.1, imgsz=1280,\n",
    "                  exist_ok=True,\n",
    "                  conf=0.5, iou=0.5,\n",
    "                  optimizer=\"auto\", seed=0,\n",
    "                  box=7.5, cls=0.5, dfl=1.5,\n",
    "                  lr0=0.01,\n",
    "                  close_mosaic=0,\n",
    "                  degrees=0.0, translate=0.1, scale=0.5, shear=0.0,\n",
    "                  perspective=0.0, flipud=0.0, fliplr=0.5, \n",
    "                  mosaic=0.0, mixup=0.0,\n",
    "                  deterministic=True, verbose=True,\n",
    "                  pretrained=True)\n",
    "\n",
    "trainer = DetectionTrainer(overrides=train_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "764bbb11-2f69-495d-ae58-2b226bee4d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /usr/src/ultralytics/runs/detect/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mg1y5x3\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/fisheye_challenge/wandb/run-20240308_194114-4340nstv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/g1y5x3/YOLOv8/runs/4340nstv' target=\"_blank\">train</a></strong> to <a href='https://wandb.ai/g1y5x3/YOLOv8' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/g1y5x3/YOLOv8' target=\"_blank\">https://wandb.ai/g1y5x3/YOLOv8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/g1y5x3/YOLOv8/runs/4340nstv' target=\"_blank\">https://wandb.ai/g1y5x3/YOLOv8/runs/4340nstv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      3049  utils.DeformableConv                         [3, 80, 3, 2]                 \n",
      "  1                  -1  1    134960  utils.DeformableConv                         [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8722783  ultralytics.nn.modules.head.Detect           [5, [320, 640, 640]]          \n",
      "YOLOv8x_dcn summary: 370 layers, 68177592 parameters, 68177576 gradients\n",
      "\n",
      "config pretrained: True\n",
      "Transferred 589/599 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /workspace/FishEye8k/dataset/Fisheye8K_all_including_train/train/labels.cache... 529 images, 0 backgrounds, 0 corrupt: 100%|██████████| 529/529 [00:00<?, ?it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8)), RandomBrightnessContrast(p=0.01, brightness_limit=(-0.2, 0.2), contrast_limit=(-0.2, 0.2), brightness_by_max=True), RandomGamma(p=0.01, gamma_limit=(80, 120))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /workspace/FishEye8k/dataset/Fisheye8K_all_including_train/test/labels.cache... 2712 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2712/2712 [00:00<?, ?it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /usr/src/ultralytics/runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 97 weight(decay=0.0), 108 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mWARNING ⚠️ TensorBoard graph visualization failure Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument min in method wrapper_CUDA_clamp_Tensor)\n",
      "Image sizes 1280 train, 1280 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/usr/src/ultralytics/runs/detect/train\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/133 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: compute_grad_input does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /opt/conda/conda-bld/pytorch_1704987394225/work/aten/src/ATen/Context.cpp:79.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "        1/1      16.7G      1.604      1.796      1.427         18       1280: 100%|██████████| 133/133 [01:17<00:00,  1.72it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 339/339 [01:51<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2712      45145       0.15      0.151      0.115     0.0605\n",
      "\n",
      "1 epochs completed in 0.055 hours.\n",
      "Optimizer stripped from /usr/src/ultralytics/runs/detect/train/weights/last.pt, 136.9MB\n",
      "Optimizer stripped from /usr/src/ultralytics/runs/detect/train/weights/best.pt, 136.9MB\n",
      "\n",
      "Validating /usr/src/ultralytics/runs/detect/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.19 🚀 Python-3.10.13 torch-2.2.0 CUDA:0 (NVIDIA GeForce RTX 3090, 24260MiB)\n",
      "YOLOv8x_dcn summary (fused): 275 layers, 68148792 parameters, 0 gradients\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 339/339 [01:45<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       2712      45145      0.151      0.151      0.115     0.0605\n",
      "                   bus       2712        930      0.062      0.104     0.0345     0.0201\n",
      "                  bike       2712      26270       0.39      0.286      0.297      0.146\n",
      "                   car       2712      14113      0.201      0.249      0.184       0.11\n",
      "            pedestrian       2712       2633      0.102      0.116     0.0595     0.0271\n",
      "                 truck       2712       1199          0          0          0          0\n",
      "Speed: 0.5ms preprocess, 32.1ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1m/usr/src/ultralytics/runs/detect/train\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='139.526 MB of 139.526 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>▁</td></tr><tr><td>lr/pg1</td><td>▁</td></tr><tr><td>lr/pg2</td><td>▁</td></tr><tr><td>metrics/mAP50(B)</td><td>▁</td></tr><tr><td>metrics/mAP50-95(B)</td><td>▁</td></tr><tr><td>metrics/precision(B)</td><td>▁</td></tr><tr><td>metrics/recall(B)</td><td>▁</td></tr><tr><td>model/GFLOPs</td><td>▁</td></tr><tr><td>model/parameters</td><td>▁</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>▁</td></tr><tr><td>train/box_loss</td><td>▁</td></tr><tr><td>train/cls_loss</td><td>▁</td></tr><tr><td>train/dfl_loss</td><td>▁</td></tr><tr><td>val/box_loss</td><td>▁</td></tr><tr><td>val/cls_loss</td><td>▁</td></tr><tr><td>val/dfl_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>0.00037</td></tr><tr><td>lr/pg1</td><td>0.00037</td></tr><tr><td>lr/pg2</td><td>0.00037</td></tr><tr><td>metrics/mAP50(B)</td><td>0.11493</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.06052</td></tr><tr><td>metrics/precision(B)</td><td>0.15117</td></tr><tr><td>metrics/recall(B)</td><td>0.15107</td></tr><tr><td>model/GFLOPs</td><td>0.0</td></tr><tr><td>model/parameters</td><td>68177592</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>32.123</td></tr><tr><td>train/box_loss</td><td>1.60361</td></tr><tr><td>train/cls_loss</td><td>1.79562</td></tr><tr><td>train/dfl_loss</td><td>1.42701</td></tr><tr><td>val/box_loss</td><td>2.25503</td></tr><tr><td>val/cls_loss</td><td>3.97129</td></tr><tr><td>val/dfl_loss</td><td>1.82572</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">train</strong> at: <a href='https://wandb.ai/g1y5x3/YOLOv8/runs/4340nstv' target=\"_blank\">https://wandb.ai/g1y5x3/YOLOv8/runs/4340nstv</a><br/> View job at <a href='https://wandb.ai/g1y5x3/YOLOv8/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjkyNjc2Ng==/version_details/v1' target=\"_blank\">https://wandb.ai/g1y5x3/YOLOv8/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjE0NjkyNjc2Ng==/version_details/v1</a><br/>Synced 6 W&B file(s), 30 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_194114-4340nstv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12458ec6-a0e3-45b8-bb90-fcd2d6ea2d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 3, 3, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dcn1_offset_conv = trainer.model.model[0].offset_conv.weight.data.cpu().numpy()\n",
    "dcn1_offset_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d47eb4e-cd76-482a-a897-94bd0db8a092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00015067 -5.8196e-05  6.1181e-05]\n",
      " [ -0.0005033 -0.00047244  -0.0001424]\n",
      " [-0.00050301 -0.00049408 -0.00024172]]\n"
     ]
    }
   ],
   "source": [
    "print(dcn1_offset_conv[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4608de2e-486e-4128-81df-3e9da7369118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 18 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(3, 6)\n",
    "for i in range(18):\n",
    "    row = i // 6\n",
    "    col = i % 6\n",
    "    axs[row,col].imshow(dcn1_offset_conv[i,0,:])\n",
    "    axs[row,col].get_xaxis().set_visible(False)\n",
    "    axs[row,col].get_yaxis().set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eb072f52-8b01-4aae-af4c-03570fb1c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "valdata_iterator = iter(trainer.validator.dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56ae531-dd82-4fd1-a281-a0e03ef9012a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
