apiVersion: batch/v1
kind: Job
metadata: 
  name: yolov8-fisheye-trainer-2gpus
spec:
  ttlSecondsAfterFinished: 100
  template:
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: nvidia.com/gpu.product
                operator: In
                values:
                - NVIDIA-A100-SXM4-80GB
      volumes:
      - name: dshm
        emptyDir:
          medium: Memory
      - name: code
        persistentVolumeClaim:
          claimName: fisheye-challenge

      containers:
      - name: gpu-container
        image: gitlab-registry.nrp-nautilus.io/yg5d6/yolov8
        command: ["/bin/sh", "-c"]
        # single gpu
        # python yolov8x_train_fisheye.py -devices 1 -epoch 250 -bs 16 -name yolov8x_full_train;
        # multigpu - make sure requesting at least 64G of RAM
        # python -m torch.distributed.run --nproc_per_node 2 yolov8x_train_fisheye.py -devices 2 -epoch 250 -bs 32 -name yolov8x_full_train;
        args:
        - pip install cython;
          cp -r /workspace/code/cocoapi /workspace/;
          cd /workspace/code/cocoapi/PythonAPI;
          make;
          pip install -e .;
          cd /workspace/FishEye8k/;
          mkdir dataset;
          tar -xvf Fisheye8K_all_including_train.tar.gz -C dataset/;
          wandb login a9d4d981ca28ba6b6729e2a29464674ca243b891;
          cp -r /workspace/code/fisheye_challenge .;
          cd fisheye_challenge;
          python -m torch.distributed.run --nproc_per_node 2 yolov8x_train_fisheye.py -devices 2 -epoch 250 -bs 32 -name yolov8x_full_train;
        resources:
          limits:
            memory: "64G"
            cpu: "8"
            nvidia.com/gpu: "2"
          requests:
            memory: "64G"
            cpu: "8"
            nvidia.com/gpu: "2"
        volumeMounts:
        - name: dshm
          mountPath: /dev/shm
        - name: code
          mountPath: /workspace/code
      restartPolicy: Never